{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q0y63c_8FEy7",
        "oAh4a3ZhAN0f",
        "AFXyCv-QAeiP",
        "YUoAG0z-AzVB",
        "YxjMTMWzImLm",
        "t6vS3vp5I4Ow",
        "KiaM0wvhMk5k",
        "4_oAp-PT3Cmf",
        "EV12o0yFRFER",
        "ObOEPJEFJdKF",
        "1Ba98VTWJftA",
        "CDATxA1xJsD-",
        "X4HgsYMMKR7u",
        "Sus8TWIEKIoq",
        "3dRUmQNUJ1wS",
        "KDSe2NbJKw4T"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoCalca/Ratings/blob/master/XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To try XGBoost github code"
      ],
      "metadata": {
        "id": "rjTIlcz0fSHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "vflrqJKOfVFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6aaf949-930b-47a3-8846-f39e7426e688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think to change the directory"
      ],
      "metadata": {
        "id": "wvUPdVBhiZmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /gdrive/MyDrive/Master_Thesis/"
      ],
      "metadata": {
        "id": "MyXTkwAqfYG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f6697a-383b-4d8a-bb39-b14a207720d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/Master_Thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import xlrd\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "from abc import ABC,abstractmethod\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import sklearn\n",
        "from math import sqrt\n",
        "#from treeinterpreter import treeinterpreter as ti\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.tree import _tree\n",
        "from pandas.plotting import scatter_matrix\n",
        "from xlrd.xlsx import X12Styles\n",
        "import pandas_profiling\n",
        "from statsmodels.tsa.arima_model import ARMA\n",
        "import statsmodels.api as sm\n",
        "from sklearn import linear_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv_qydZLfYLG",
        "outputId": "4bf3cd39-71a7-427b-d869-b376e92c4bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First the preprocessing"
      ],
      "metadata": {
        "id": "waKn8aXtfpQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Upload and Preprocessing"
      ],
      "metadata": {
        "id": "q0y63c_8FEy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We upload the general data"
      ],
      "metadata": {
        "id": "xrqNKq0dRxQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rating_history = xlrd.open_workbook(\"LT_FC_rating_History_SP.xlsx\")\n",
        "SP_Data = xlrd.open_workbook(\"report_S&P.xlsx\")"
      ],
      "metadata": {
        "id": "Ol_D7525FEEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We extact the data of each sheet"
      ],
      "metadata": {
        "id": "jCjbAmt5YKL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rating_history_sheet = Rating_history.sheet_by_index(0)\n",
        "SP_Economic_Data = SP_Data.sheet_by_index(0) # GDP/Capita\n",
        "SP_Monetary_Data = SP_Data.sheet_by_index(1) # Real GDP growth\n",
        "SP_GG_Data = SP_Data.sheet_by_index(2) # General Government\n",
        "SP_BoP_Data = SP_Data.sheet_by_index(3) # Balance Of Payment\n",
        "SP_EB_Data = SP_Data.sheet_by_index(4) # External Balance \n",
        "SP_CGDaB_Data = SP_Data.sheet_by_index(5) # CGDaB_Data"
      ],
      "metadata": {
        "id": "l_QSSJS_FEIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We extract each interesting data one by one"
      ],
      "metadata": {
        "id": "oI6kyPgCYYDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of the country and their code\n",
        "Country_List_Name = [Rating_history_sheet.cell_value(i, 0) for i in range(2, 139)]\n",
        "Country_List_Code = [Rating_history_sheet.cell_value(i, 1) for i in range(2, 139)]\n",
        "CLN_tot = Country_List_Name*7 # For after\n",
        "CLC_tot = Country_List_Code*7 # For after\n",
        "# List of the rating\n",
        "Rating_2015 = [Rating_history_sheet.cell_value(i, 2) for i in range(2, 139)]\n",
        "Rating_2016 = [Rating_history_sheet.cell_value(i, 3) for i in range(2, 139)]\n",
        "Rating_2017 = [Rating_history_sheet.cell_value(i, 4) for i in range(2, 139)]\n",
        "Rating_2018 = [Rating_history_sheet.cell_value(i, 5) for i in range(2, 139)]\n",
        "Rating_2019 = [Rating_history_sheet.cell_value(i, 6) for i in range(2, 139)]\n",
        "Rating_2020 = [Rating_history_sheet.cell_value(i, 7) for i in range(2, 139)]\n",
        "Rating_2021 = [Rating_history_sheet.cell_value(i, 8) for i in range(2, 139)]\n",
        "Rating_Global_Data = Rating_2015+Rating_2016+Rating_2017+Rating_2018+Rating_2019+Rating_2020+Rating_2021"
      ],
      "metadata": {
        "id": "RoBH_N83EsRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GDP/Capita --> after remove a few data problematic we will take the log\n",
        "GDP_per_Capita_2015 = [SP_Economic_Data.cell_value(i, 23) for i in range(5, 142)]\n",
        "GDP_per_Capita_2016 = [SP_Economic_Data.cell_value(i, 24) for i in range(5, 142)]\n",
        "GDP_per_Capita_2017 = [SP_Economic_Data.cell_value(i, 25) for i in range(5, 142)]\n",
        "GDP_per_Capita_2018 = [SP_Economic_Data.cell_value(i, 26) for i in range(5, 142)]\n",
        "GDP_per_Capita_2019 = [SP_Economic_Data.cell_value(i, 27) for i in range(5, 142)]\n",
        "GDP_per_Capita_2020 = [SP_Economic_Data.cell_value(i, 28) for i in range(5, 142)]\n",
        "GDP_per_Capita_2021 = [SP_Economic_Data.cell_value(i, 29) for i in range(5, 142)]\n",
        "GDP_per_Capita_Global_Data = GDP_per_Capita_2015+GDP_per_Capita_2016+GDP_per_Capita_2017+GDP_per_Capita_2018+GDP_per_Capita_2019+GDP_per_Capita_2020+GDP_per_Capita_2021"
      ],
      "metadata": {
        "id": "0tNa45zEYPAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real GDP growth (%)\n",
        "Real_GDP_Growth_2015 = [SP_Economic_Data.cell_value(i, 33) for i in range(5, 142)]\n",
        "Real_GDP_Growth_2016 = [SP_Economic_Data.cell_value(i, 34) for i in range(5, 142)]\n",
        "Real_GDP_Growth_2017 = [SP_Economic_Data.cell_value(i, 35) for i in range(5, 142)]\n",
        "Real_GDP_Growth_2018 = [SP_Economic_Data.cell_value(i, 36) for i in range(5, 142)]\n",
        "Real_GDP_Growth_2019 = [SP_Economic_Data.cell_value(i, 37) for i in range(5, 142)]\n",
        "Real_GDP_Growth_2020 = [SP_Economic_Data.cell_value(i, 33) for i in range(5, 142)]\n",
        "Real_GDP_Growth_2021 = [SP_Economic_Data.cell_value(i, 33) for i in range(5, 142)]\n",
        "Real_GDP_Growth_Global_Data = Real_GDP_Growth_2015+Real_GDP_Growth_2016+Real_GDP_Growth_2017+Real_GDP_Growth_2018+Real_GDP_Growth_2019+Real_GDP_Growth_2020+Real_GDP_Growth_2021"
      ],
      "metadata": {
        "id": "55aqFQ15QE7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Current Account Balance / GDP\n",
        "CAB_on_GDP_2015 = [SP_BoP_Data.cell_value(i,23) for i in range(5, 142)]\n",
        "CAB_on_GDP_2016 = [SP_BoP_Data.cell_value(i,24) for i in range(5, 142)]\n",
        "CAB_on_GDP_2017 = [SP_BoP_Data.cell_value(i,25) for i in range(5, 142)]\n",
        "CAB_on_GDP_2018 = [SP_BoP_Data.cell_value(i,26) for i in range(5, 142)]\n",
        "CAB_on_GDP_2019 = [SP_BoP_Data.cell_value(i,27) for i in range(5, 142)]\n",
        "CAB_on_GDP_2020 = [SP_BoP_Data.cell_value(i,28) for i in range(5, 142)]\n",
        "CAB_on_GDP_2021 = [SP_BoP_Data.cell_value(i,29) for i in range(5, 142)]\n",
        "CAB_on_GDP_Global_Data = CAB_on_GDP_2015+CAB_on_GDP_2016+CAB_on_GDP_2017+CAB_on_GDP_2018+CAB_on_GDP_2019+CAB_on_GDP_2020+CAB_on_GDP_2021"
      ],
      "metadata": {
        "id": "55W4LyfGVmc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net General Government Debt / GDP\n",
        "NGGD_on_GDP_2015 = [SP_GG_Data.cell_value(i, 83) for i in range(5, 142)]\n",
        "NGGD_on_GDP_2016 = [SP_GG_Data.cell_value(i, 84) for i in range(5, 142)]\n",
        "NGGD_on_GDP_2017 = [SP_GG_Data.cell_value(i, 85) for i in range(5, 142)]\n",
        "NGGD_on_GDP_2018 = [SP_GG_Data.cell_value(i, 86) for i in range(5, 142)]\n",
        "NGGD_on_GDP_2019 = [SP_GG_Data.cell_value(i, 87) for i in range(5, 142)]\n",
        "NGGD_on_GDP_2020 = [SP_GG_Data.cell_value(i, 88) for i in range(5, 142)]\n",
        "NGGD_on_GDP_2021 = [SP_GG_Data.cell_value(i, 83) for i in range(5, 142)]\n",
        "Rating_Global_Data = Rating_2015+Rating_2016+Rating_2017+Rating_2018+Rating_2019+Rating_2020+Rating_2021\n",
        "NGGD_on_GDP_Global_Data = NGGD_on_GDP_2015+NGGD_on_GDP_2016+NGGD_on_GDP_2017+NGGD_on_GDP_2018+NGGD_on_GDP_2019+NGGD_on_GDP_2020+NGGD_on_GDP_2021"
      ],
      "metadata": {
        "id": "j6r27I1eQFaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Narrow Net External Debt / CARs\n",
        "NNED_on_CARs_2015 = [SP_EB_Data.cell_value(i, 3) for i in range(5, 142)]\n",
        "NNED_on_CARs_2016 = [SP_EB_Data.cell_value(i, 4) for i in range(5, 142)]\n",
        "NNED_on_CARs_2017 = [SP_EB_Data.cell_value(i, 5) for i in range(5, 142)]\n",
        "NNED_on_CARs_2018 = [SP_EB_Data.cell_value(i, 6) for i in range(5, 142)]\n",
        "NNED_on_CARs_2019 = [SP_EB_Data.cell_value(i, 7) for i in range(5, 142)]\n",
        "NNED_on_CARs_2020 = [SP_EB_Data.cell_value(i, 8) for i in range(5, 142)]\n",
        "NNED_on_CARs_2021 = [SP_EB_Data.cell_value(i, 9) for i in range(5, 142)]\n",
        "NNED_on_CARs_Global_Data = NNED_on_CARs_2015+NNED_on_CARs_2016+NNED_on_CARs_2017+NNED_on_CARs_2018+NNED_on_CARs_2019+NNED_on_CARs_2020+NNED_on_CARs_2021"
      ],
      "metadata": {
        "id": "djyujbdlkTxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General Government Balance / GDP\n",
        "GGB_on_GDP_2015 = [SP_GG_Data.cell_value(i, 3) for i in range(5, 142)]\n",
        "GGB_on_GDP_2016 = [SP_GG_Data.cell_value(i, 4) for i in range(5, 142)]\n",
        "GGB_on_GDP_2017 = [SP_GG_Data.cell_value(i, 5) for i in range(5, 142)]\n",
        "GGB_on_GDP_2018 = [SP_GG_Data.cell_value(i, 6) for i in range(5, 142)]\n",
        "GGB_on_GDP_2019 = [SP_GG_Data.cell_value(i, 7) for i in range(5, 142)]\n",
        "GGB_on_GDP_2020 = [SP_GG_Data.cell_value(i, 8) for i in range(5, 142)]\n",
        "GGB_on_GDP_2021 = [SP_GG_Data.cell_value(i, 9) for i in range(5, 142)]\n",
        "GGB_on_GDP_Global_Data = GGB_on_GDP_2015+GGB_on_GDP_2016+GGB_on_GDP_2017+GGB_on_GDP_2018+GGB_on_GDP_2019+GGB_on_GDP_2020+GGB_on_GDP_2021"
      ],
      "metadata": {
        "id": "-5ArcJvz0RN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year_list = [2015]*137+[2016]*137+[2017]*137+[2018]*137+[2019]*137+[2020]*137+[2021]*137"
      ],
      "metadata": {
        "id": "5BzG9E5-8YVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Check and put well**"
      ],
      "metadata": {
        "id": "kxaEbn_v5d9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(CLN_tot))\n",
        "print(len(CLC_tot))\n",
        "print(len(Rating_Global_Data))\n",
        "print(len(GDP_per_Capita_Global_Data))\n",
        "print(len(Real_GDP_Growth_Global_Data))\n",
        "print(len(CAB_on_GDP_Global_Data))\n",
        "print(len(NGGD_on_GDP_Global_Data))\n",
        "print(len(NNED_on_CARs_Global_Data))\n",
        "print(len(GGB_on_GDP_Global_Data))\n",
        "print(len(year_list))"
      ],
      "metadata": {
        "id": "OiC11cTw0RRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ab1343-a9c1-4602-a27e-f5a3d254deb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "959\n",
            "959\n",
            "959\n",
            "959\n",
            "959\n",
            "959\n",
            "959\n",
            "959\n",
            "959\n",
            "959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**We remove the Data where we don't have the rating**"
      ],
      "metadata": {
        "id": "oAh4a3ZhAN0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rating_Clear_Data = []\n",
        "nb_false = 0\n",
        "for i in range(len(Rating_Global_Data)):\n",
        "  if Rating_Global_Data[i] == 'N':\n",
        "    CLN_tot.pop(i-nb_false)\n",
        "    CLC_tot.pop(i-nb_false)\n",
        "    GDP_per_Capita_Global_Data.pop(i-nb_false)\n",
        "    Real_GDP_Growth_Global_Data.pop(i-nb_false)\n",
        "    CAB_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    NGGD_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    NNED_on_CARs_Global_Data.pop(i-nb_false)\n",
        "    GGB_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    year_list.pop(i-nb_false)\n",
        "    nb_false+=1\n",
        "  else:\n",
        "    Rating_Clear_Data.append(Rating_Global_Data[i])"
      ],
      "metadata": {
        "id": "bna4NXQV0RUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rating_Global_Data = Rating_Clear_Data\n",
        "print(len(CLN_tot))\n",
        "print(len(CLC_tot))\n",
        "print(len(Rating_Global_Data))\n",
        "print(len(GDP_per_Capita_Global_Data))\n",
        "print(len(Real_GDP_Growth_Global_Data))\n",
        "print(len(CAB_on_GDP_Global_Data))\n",
        "print(len(NGGD_on_GDP_Global_Data))\n",
        "print(len(NNED_on_CARs_Global_Data))\n",
        "print(len(GGB_on_GDP_Global_Data))\n",
        "print(len(year_list))"
      ],
      "metadata": {
        "id": "VLE4TZyGR8AH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0b9051-74b5-4370-d62f-ac8987244491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "925\n",
            "925\n",
            "925\n",
            "925\n",
            "925\n",
            "925\n",
            "925\n",
            "925\n",
            "925\n",
            "925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**We check if our data is well typed**"
      ],
      "metadata": {
        "id": "AFXyCv-QAeiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*When there are a lack of Data in S&P file, there put a string such that N/A*"
      ],
      "metadata": {
        "id": "U10zFh3hAjpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal : Check if there are just float / double / int in the list ie in our case : no str\n",
        "def check_list(a):\n",
        "  # Input a : list we want to check\n",
        "  # Output test : return True if there are no str in the list, False otherwise\n",
        "  test = True\n",
        "  for i in range(len(a)):\n",
        "    if type(a[i]) == str:\n",
        "      test = False\n",
        "  return(test)"
      ],
      "metadata": {
        "id": "v-0tfpdZ624j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(GDP_per_Capita_Global_Data)"
      ],
      "metadata": {
        "id": "0Q_8XPop_AEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c55b358-2186-4609-bf29-2c2296915f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(GDP_per_Capita_Global_Data)"
      ],
      "metadata": {
        "id": "I-eArZ8AUbLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22601a2f-96d8-42d6-a93e-21fc8d315466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(Real_GDP_Growth_Global_Data)"
      ],
      "metadata": {
        "id": "Ng8oKEit_Kvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0014bc52-908c-4ef2-9df6-fa2a81d00c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(CAB_on_GDP_Global_Data)"
      ],
      "metadata": {
        "id": "hR6C7cBI_ddS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c76439-3585-4ace-ff4b-41febd3ac936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAB_on_GDP_Clear_Data = []\n",
        "nb_false = 0\n",
        "for i in range(len(CAB_on_GDP_Global_Data)):\n",
        "  if type(CAB_on_GDP_Global_Data[i]) == str:\n",
        "    CLN_tot.pop(i-nb_false)\n",
        "    CLC_tot.pop(i-nb_false)\n",
        "    Rating_Global_Data.pop(i-nb_false)\n",
        "    Real_GDP_Growth_Global_Data.pop(i-nb_false)\n",
        "    GDP_per_Capita_Global_Data.pop(i-nb_false)\n",
        "    NGGD_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    NNED_on_CARs_Global_Data.pop(i-nb_false)\n",
        "    GGB_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    year_list.pop(i-nb_false)\n",
        "    nb_false += 1\n",
        "  else:\n",
        "    CAB_on_GDP_Clear_Data.append(CAB_on_GDP_Global_Data[i])\n",
        "CAB_on_GDP_Global_Data = CAB_on_GDP_Clear_Data"
      ],
      "metadata": {
        "id": "4oBZ7NYsUhZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(CAB_on_GDP_Global_Data)"
      ],
      "metadata": {
        "id": "9Hd47bpoXPGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7f37da-9fd7-45eb-d3bc-a7d5c999fb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(NGGD_on_GDP_Global_Data)"
      ],
      "metadata": {
        "id": "7296XGb4_hp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273ebc5b-5181-437d-9b91-c1493db8e489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(NNED_on_CARs_Global_Data)"
      ],
      "metadata": {
        "id": "WURgvS8L_m5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2079d9a5-f6ab-4456-db2a-abd6d7089e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NNED_on_CARs_Clear_Data = []\n",
        "nb_false = 0\n",
        "for i in range(len(NNED_on_CARs_Global_Data)):\n",
        "  if type(NNED_on_CARs_Global_Data[i]) == str:\n",
        "    CLN_tot.pop(i-nb_false)\n",
        "    CLC_tot.pop(i-nb_false)\n",
        "    Rating_Global_Data.pop(i-nb_false)\n",
        "    Real_GDP_Growth_Global_Data.pop(i-nb_false)\n",
        "    GDP_per_Capita_Global_Data.pop(i-nb_false)\n",
        "    NGGD_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    CAB_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    GGB_on_GDP_Global_Data.pop(i-nb_false)\n",
        "    year_list.pop(i-nb_false)\n",
        "    nb_false += 1\n",
        "  else:\n",
        "    NNED_on_CARs_Clear_Data.append(NNED_on_CARs_Global_Data[i])\n",
        "NNED_on_CARs_Global_Data = NNED_on_CARs_Clear_Data"
      ],
      "metadata": {
        "id": "jm1Wq6idXucq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(NNED_on_CARs_Global_Data)"
      ],
      "metadata": {
        "id": "0zxTaZ_tYEfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71136aaa-1fd5-4d14-c7a9-9cb30523d333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_list(GGB_on_GDP_Global_Data)"
      ],
      "metadata": {
        "id": "dJSnN0Ff_sRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4262a2d4-cdd6-44dd-8a42-8123bf075cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(CLN_tot))\n",
        "print(len(CLC_tot))\n",
        "print(len(Rating_Global_Data))\n",
        "print(len(GDP_per_Capita_Global_Data))\n",
        "print(len(Real_GDP_Growth_Global_Data))\n",
        "print(len(CAB_on_GDP_Global_Data))\n",
        "print(len(NGGD_on_GDP_Global_Data))\n",
        "print(len(NNED_on_CARs_Global_Data))\n",
        "print(len(GGB_on_GDP_Global_Data))\n",
        "print(len(year_list))"
      ],
      "metadata": {
        "id": "Vu0qAelk64Wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73345449-2904-4665-9a9c-3a734fe5f607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "872\n",
            "872\n",
            "872\n",
            "872\n",
            "872\n",
            "872\n",
            "872\n",
            "872\n",
            "872\n",
            "872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now that the Data is well, we can apply the log to the GDP/Capita"
      ],
      "metadata": {
        "id": "YUoAG0z-AzVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_GDP_per_Capita_Global_Data = list(np.log(GDP_per_Capita_Global_Data))\n",
        "len(log_GDP_per_Capita_Global_Data)"
      ],
      "metadata": {
        "id": "FrCHWno266ZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b8fb14-c266-4fe1-ffad-0a889d670b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "872"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Useful functions"
      ],
      "metadata": {
        "id": "YxjMTMWzImLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal : translate a str rating like 'AA' into his numerical rating according to S&P method\n",
        "def Rating_from_stg_to_num(a):\n",
        "  # Input a : str \n",
        "  # Output n : int corresponding to his note\n",
        "  if a == 'AAA':\n",
        "    n = 20\n",
        "  elif a == 'AA+':\n",
        "    n = 19\n",
        "  elif a == 'AA':\n",
        "    n = 18\n",
        "  elif a == 'AA-':\n",
        "    n = 17\n",
        "  elif a == 'A+':\n",
        "    n = 16\n",
        "  elif a == 'A':\n",
        "    n = 15\n",
        "  elif a == 'A-':\n",
        "    n = 14\n",
        "  elif a == 'BBB+':\n",
        "    n = 13\n",
        "  elif a == 'BBB' :\n",
        "    n = 12\n",
        "  elif a == 'BBB-':\n",
        "    n = 11\n",
        "  elif a == 'BB+':\n",
        "    n = 10\n",
        "  elif a == 'BB':\n",
        "    n = 9\n",
        "  elif a == 'BB-':\n",
        "    n = 8\n",
        "  elif a == 'B+':\n",
        "    n = 7\n",
        "  elif a == 'B':\n",
        "    n = 6\n",
        "  elif a == 'B-':\n",
        "    n = 5\n",
        "  elif a == 'CCC+':\n",
        "    n = 4\n",
        "  elif a == 'CCC':\n",
        "    n = 3\n",
        "  elif a == 'CCC-':\n",
        "    n = 2\n",
        "  elif a == \"\":\n",
        "    n = \"\"\n",
        "  else:\n",
        "    n = 1\n",
        "  return(n)\n"
      ],
      "metadata": {
        "id": "9QnsvxwC_3I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal : translate a float rating into his str rating according to S&P\n",
        "# Note that we make a choice to give C for a rating lower than 1.5 since the numerical rating is less precised\n",
        "def Rating_from_num_to_stg(n):\n",
        "  # Input n : int \n",
        "  # Output a : str corresponding to his note\n",
        "  if n > 19.5:\n",
        "    a = 'AAA'\n",
        "  elif n > 18.5:\n",
        "    a = 'AA+'\n",
        "  elif n > 17.5:\n",
        "    a = 'AA'\n",
        "  elif n > 16.5:\n",
        "    a = 'AA-'\n",
        "  elif n > 15.5:\n",
        "    a = 'A+'\n",
        "  elif n > 14.5:\n",
        "    a = 'A'\n",
        "  elif n > 13.5:\n",
        "    a = 'A-'\n",
        "  elif n > 12.5:\n",
        "    a = 'BBB+'\n",
        "  elif n > 11.5 :\n",
        "    a = 'BBB'\n",
        "  elif n > 10.5:\n",
        "    a = 'BBB-'\n",
        "  elif n > 9.5:\n",
        "    a = 'BB+'\n",
        "  elif n > 8.5:\n",
        "    a = 'BB'\n",
        "  elif n > 7.5:\n",
        "    a = 'BB-'\n",
        "  elif n > 6.5:\n",
        "    a = 'B+'\n",
        "  elif n > 5.5:\n",
        "    a = 'B'\n",
        "  elif n > 4.5:\n",
        "    a = 'B-'\n",
        "  elif n > 3.5:\n",
        "    a = 'CCC+'\n",
        "  elif n > 2.5:\n",
        "    a = 'CCC'\n",
        "  elif n > 1.5:\n",
        "    a = 'CCC-'\n",
        "  else:\n",
        "    a = 'C'  # By choice : here we have lost some info then we have to consider equivalent CC, C and SD even if it's not true in reality\n",
        "  return(a)\n"
      ],
      "metadata": {
        "id": "ehoCV5P_AK2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal : Convert the str rating into his 'global' rating category ie e.g. 'A+' into 'A'\n",
        "def Global_Rating(a):\n",
        "  # Input : str\n",
        "  # Output : str\n",
        "  b = a\n",
        "  if a[-1] == '+' or a[-1] == '-':\n",
        "    b = a[:-1]\n",
        "  return(b)"
      ],
      "metadata": {
        "id": "cTXLzTWPDX6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We convert the ratings in notches"
      ],
      "metadata": {
        "id": "t6vS3vp5I4Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rating_Global_Data_num = []\n",
        "for a in Rating_Global_Data:\n",
        "  Rating_Global_Data_num.append(Rating_from_stg_to_num(a))"
      ],
      "metadata": {
        "id": "RIVV8lx2DX9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We add different useful list"
      ],
      "metadata": {
        "id": "KiaM0wvhMk5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Global_Rating_Global_Data = []\n",
        "for a in Rating_Global_Data:\n",
        "  Global_Rating_Global_Data.append(Global_Rating(a))"
      ],
      "metadata": {
        "id": "by01HLbUMu0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G20 = ['Canada', 'Japan', 'United States', 'United Kingdom', 'France', 'Germany', 'Italy', 'Australia', 'Korea','Mexico',\n",
        "       'Turkey', 'Argentina', 'Brazil', 'China', 'India', 'Indonesia', 'Russia', 'Saudi Arabia', 'South Africa']\n",
        "# Korea means of course South Korea (we use the same name than in S&P)\n"
      ],
      "metadata": {
        "id": "f3fDcz-kXP_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "No_G20 = []\n",
        "for c in CLN_tot:\n",
        "  if (c not in G20) and (c not in No_G20):\n",
        "    No_G20.append(c)"
      ],
      "metadata": {
        "id": "mrtU_XJiqIXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OECD = ['Australia', 'Austria', 'Belgium', 'Canada', 'Chile', 'Colombia', 'Costa Rica', 'Czech Rep.', 'Denmark', 'Estonia',\n",
        "        'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Israel', 'Italy', 'Japan',\n",
        "        'Korea', 'Latvia', 'Lithuania', 'Luxembourg', 'Mexico', 'Netherlands', 'New Zealand', 'Norway', 'Poland',\n",
        "        'Portugal', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'United Kingdom',\n",
        "        'United States']"
      ],
      "metadata": {
        "id": "KNVxWTHPOPIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "No_OECD = []\n",
        "for c in CLN_tot:\n",
        "  if (c not in OECD) and (c not in No_OECD):\n",
        "    No_OECD.append(c)"
      ],
      "metadata": {
        "id": "oju3SwWCOPQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation of the pandas Dataframe"
      ],
      "metadata": {
        "id": "A8x3fYBrKxl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have the dataframe with global Data"
      ],
      "metadata": {
        "id": "8k5U5TycW-vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = pd.MultiIndex.from_arrays(np.array([np.array(CLN_tot), np.array(CLC_tot), np.array(year_list)]), \n",
        "                                  names=[\"Country Name\", \"Country Code\", \"Year\"])\n",
        "\n",
        "Data1 = pd.DataFrame({'Rating (Num)': Rating_Global_Data_num, 'log(GDP/Capita)': log_GDP_per_Capita_Global_Data, \n",
        "                          'Real GDP Growth': Real_GDP_Growth_Global_Data, 'Current Account Balance / GDP': CAB_on_GDP_Global_Data,\n",
        "                          'Net General Government Debt / GDP' : NGGD_on_GDP_Global_Data,\n",
        "                          'Narrow Net External Debt / CARs' : NNED_on_CARs_Global_Data,\n",
        "                          'General Government Balance / GDP' : GGB_on_GDP_Global_Data},\n",
        "                      index = index)\n",
        "\n",
        "Data2 = pd.DataFrame({'Rating': Rating_Global_Data, 'log(GDP/Capita)': log_GDP_per_Capita_Global_Data, \n",
        "                          'Real GDP Growth': Real_GDP_Growth_Global_Data, 'Current Account Balance / GDP': CAB_on_GDP_Global_Data,\n",
        "                          'Net General Government Debt / GDP' : NGGD_on_GDP_Global_Data,\n",
        "                          'Narrow Net External Debt / CARs' : NNED_on_CARs_Global_Data,\n",
        "                          'General Government Balance / GDP' : GGB_on_GDP_Global_Data},\n",
        "                      index = index)\n",
        "\n",
        "Data3 = pd.DataFrame({'Rating (Global)': Global_Rating_Global_Data, 'log(GDP/Capita)': log_GDP_per_Capita_Global_Data, \n",
        "                          'Real GDP Growth': Real_GDP_Growth_Global_Data, 'Current Account Balance / GDP': CAB_on_GDP_Global_Data,\n",
        "                          'Net General Government Debt / GDP' : NGGD_on_GDP_Global_Data,\n",
        "                          'Narrow Net External Debt / CARs' : NNED_on_CARs_Global_Data,\n",
        "                          'General Government Balance / GDP' : GGB_on_GDP_Global_Data},\n",
        "                      index = index)\n"
      ],
      "metadata": {
        "id": "g0Jpku8mF3iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data1.head()"
      ],
      "metadata": {
        "id": "Z-oK4WhyF3nX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "9c37a1b9-46d7-4736-c211-18d655f50a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Rating (Num)  log(GDP/Capita)  \\\n",
              "Country Name Country Code Year                                  \n",
              "Albania      AL           2015             6         8.283956   \n",
              "Angola       AO           2015             7         8.335846   \n",
              "Argentina    AR           2015             1         9.612653   \n",
              "Aruba        AW           2015            13        10.208346   \n",
              "Australia    AU           2015            20        10.946203   \n",
              "\n",
              "                                Real GDP Growth  \\\n",
              "Country Name Country Code Year                    \n",
              "Albania      AL           2015             2.22   \n",
              "Angola       AO           2015             0.94   \n",
              "Argentina    AR           2015             2.73   \n",
              "Aruba        AW           2015             3.52   \n",
              "Australia    AU           2015             2.19   \n",
              "\n",
              "                                Current Account Balance / GDP  \\\n",
              "Country Name Country Code Year                                  \n",
              "Albania      AL           2015                          -8.61   \n",
              "Angola       AO           2015                          -8.84   \n",
              "Argentina    AR           2015                          -2.73   \n",
              "Aruba        AW           2015                           2.52   \n",
              "Australia    AU           2015                          -3.71   \n",
              "\n",
              "                                Net General Government Debt / GDP  \\\n",
              "Country Name Country Code Year                                      \n",
              "Albania      AL           2015                              70.34   \n",
              "Angola       AO           2015                              24.18   \n",
              "Argentina    AR           2015                              43.48   \n",
              "Aruba        AW           2015                              33.75   \n",
              "Australia    AU           2015                              12.60   \n",
              "\n",
              "                                Narrow Net External Debt / CARs  \\\n",
              "Country Name Country Code Year                                    \n",
              "Albania      AL           2015                            19.71   \n",
              "Angola       AO           2015                            35.31   \n",
              "Argentina    AR           2015                           148.49   \n",
              "Aruba        AW           2015                            10.62   \n",
              "Australia    AU           2015                           265.18   \n",
              "\n",
              "                                General Government Balance / GDP  \n",
              "Country Name Country Code Year                                    \n",
              "Albania      AL           2015                             -4.06  \n",
              "Angola       AO           2015                             -2.92  \n",
              "Argentina    AR           2015                             -4.72  \n",
              "Aruba        AW           2015                             -2.71  \n",
              "Australia    AU           2015                             -2.20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c25b6c47-ed57-4c0b-85d6-4807fee8ca97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country Name</th>\n",
              "      <th>Country Code</th>\n",
              "      <th>Year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Albania</th>\n",
              "      <th>AL</th>\n",
              "      <th>2015</th>\n",
              "      <td>6</td>\n",
              "      <td>8.283956</td>\n",
              "      <td>2.22</td>\n",
              "      <td>-8.61</td>\n",
              "      <td>70.34</td>\n",
              "      <td>19.71</td>\n",
              "      <td>-4.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Angola</th>\n",
              "      <th>AO</th>\n",
              "      <th>2015</th>\n",
              "      <td>7</td>\n",
              "      <td>8.335846</td>\n",
              "      <td>0.94</td>\n",
              "      <td>-8.84</td>\n",
              "      <td>24.18</td>\n",
              "      <td>35.31</td>\n",
              "      <td>-2.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Argentina</th>\n",
              "      <th>AR</th>\n",
              "      <th>2015</th>\n",
              "      <td>1</td>\n",
              "      <td>9.612653</td>\n",
              "      <td>2.73</td>\n",
              "      <td>-2.73</td>\n",
              "      <td>43.48</td>\n",
              "      <td>148.49</td>\n",
              "      <td>-4.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aruba</th>\n",
              "      <th>AW</th>\n",
              "      <th>2015</th>\n",
              "      <td>13</td>\n",
              "      <td>10.208346</td>\n",
              "      <td>3.52</td>\n",
              "      <td>2.52</td>\n",
              "      <td>33.75</td>\n",
              "      <td>10.62</td>\n",
              "      <td>-2.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Australia</th>\n",
              "      <th>AU</th>\n",
              "      <th>2015</th>\n",
              "      <td>20</td>\n",
              "      <td>10.946203</td>\n",
              "      <td>2.19</td>\n",
              "      <td>-3.71</td>\n",
              "      <td>12.60</td>\n",
              "      <td>265.18</td>\n",
              "      <td>-2.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c25b6c47-ed57-4c0b-85d6-4807fee8ca97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c25b6c47-ed57-4c0b-85d6-4807fee8ca97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c25b6c47-ed57-4c0b-85d6-4807fee8ca97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data2.describe(include = 'all')"
      ],
      "metadata": {
        "id": "OdbU7-H1GOYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "c5585ce6-830c-4f35-e71e-9bf7f01590af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count     872       872.000000       872.000000   \n",
              "unique     20              NaN              NaN   \n",
              "top         B              NaN              NaN   \n",
              "freq       93              NaN              NaN   \n",
              "mean      NaN         9.173384         3.109415   \n",
              "std       NaN         1.297675         3.065877   \n",
              "min       NaN         6.061294       -10.190000   \n",
              "25%       NaN         8.259782         1.740000   \n",
              "50%       NaN         9.180073         2.960000   \n",
              "75%       NaN        10.201298         4.630000   \n",
              "max       NaN        11.765265        25.180000   \n",
              "\n",
              "        Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                      872.000000                         872.000000   \n",
              "unique                            NaN                                NaN   \n",
              "top                               NaN                                NaN   \n",
              "freq                              NaN                                NaN   \n",
              "mean                        -0.975619                          35.237236   \n",
              "std                          8.416863                          67.411745   \n",
              "min                        -47.850000                        -558.870000   \n",
              "25%                         -4.050000                          20.850000   \n",
              "50%                         -1.320000                          39.940000   \n",
              "75%                          2.605000                          65.262500   \n",
              "max                         71.340000                         267.470000   \n",
              "\n",
              "        Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                        872.000000                        872.000000  \n",
              "unique                              NaN                               NaN  \n",
              "top                                 NaN                               NaN  \n",
              "freq                                NaN                               NaN  \n",
              "mean                          58.562936                         -3.312374  \n",
              "std                          130.896917                          4.615642  \n",
              "min                         -682.050000                        -28.500000  \n",
              "25%                           -0.615000                         -5.732500  \n",
              "50%                           50.030000                         -3.100000  \n",
              "75%                          119.582500                         -0.787500  \n",
              "max                          533.360000                         21.800000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-472285dd-ff61-43d2-8b06-a0329ac68be9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>872</td>\n",
              "      <td>872.000000</td>\n",
              "      <td>872.000000</td>\n",
              "      <td>872.000000</td>\n",
              "      <td>872.000000</td>\n",
              "      <td>872.000000</td>\n",
              "      <td>872.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>93</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>9.173384</td>\n",
              "      <td>3.109415</td>\n",
              "      <td>-0.975619</td>\n",
              "      <td>35.237236</td>\n",
              "      <td>58.562936</td>\n",
              "      <td>-3.312374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.297675</td>\n",
              "      <td>3.065877</td>\n",
              "      <td>8.416863</td>\n",
              "      <td>67.411745</td>\n",
              "      <td>130.896917</td>\n",
              "      <td>4.615642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>6.061294</td>\n",
              "      <td>-10.190000</td>\n",
              "      <td>-47.850000</td>\n",
              "      <td>-558.870000</td>\n",
              "      <td>-682.050000</td>\n",
              "      <td>-28.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>8.259782</td>\n",
              "      <td>1.740000</td>\n",
              "      <td>-4.050000</td>\n",
              "      <td>20.850000</td>\n",
              "      <td>-0.615000</td>\n",
              "      <td>-5.732500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>9.180073</td>\n",
              "      <td>2.960000</td>\n",
              "      <td>-1.320000</td>\n",
              "      <td>39.940000</td>\n",
              "      <td>50.030000</td>\n",
              "      <td>-3.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>10.201298</td>\n",
              "      <td>4.630000</td>\n",
              "      <td>2.605000</td>\n",
              "      <td>65.262500</td>\n",
              "      <td>119.582500</td>\n",
              "      <td>-0.787500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>11.765265</td>\n",
              "      <td>25.180000</td>\n",
              "      <td>71.340000</td>\n",
              "      <td>267.470000</td>\n",
              "      <td>533.360000</td>\n",
              "      <td>21.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-472285dd-ff61-43d2-8b06-a0329ac68be9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-472285dd-ff61-43d2-8b06-a0329ac68be9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-472285dd-ff61-43d2-8b06-a0329ac68be9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data1.info()"
      ],
      "metadata": {
        "id": "r5dz316_A71w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4510444f-3e63-4dce-9fd5-0489d5619526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "MultiIndex: 872 entries, ('Albania', 'AL', '2015') to ('Zambia', 'ZM', '2021')\n",
            "Data columns (total 7 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   Rating (Num)                       872 non-null    int64  \n",
            " 1   log(GDP/Capita)                    872 non-null    float64\n",
            " 2   Real GDP Growth                    872 non-null    float64\n",
            " 3   Current Account Balance / GDP      872 non-null    float64\n",
            " 4   Net General Government Debt / GDP  872 non-null    float64\n",
            " 5   Narrow Net External Debt / CARs    872 non-null    float64\n",
            " 6   General Government Balance / GDP   872 non-null    float64\n",
            "dtypes: float64(6), int64(1)\n",
            "memory usage: 62.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G20_Data = pd.concat([Data1.xs(G20[i]) for i in range(len(G20))])\n",
        "G20_Data.describe()"
      ],
      "metadata": {
        "id": "sVTLmi8GoXLZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "366d5f93-7fb7-4bce-d9f1-7acffe663b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating (Num)  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count    133.000000       133.000000       133.000000   \n",
              "mean      14.037594         9.773372         2.377970   \n",
              "std        4.750448         0.978841         2.453651   \n",
              "min        1.000000         7.381259        -3.550000   \n",
              "25%       11.000000         9.083060         1.060000   \n",
              "50%       14.000000         9.973967         2.190000   \n",
              "75%       18.000000        10.632882         3.040000   \n",
              "max       20.000000        11.141502         8.260000   \n",
              "\n",
              "       Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                     133.000000                         133.000000   \n",
              "mean                        0.123684                          50.458346   \n",
              "std                         3.593634                          50.245174   \n",
              "min                        -8.670000                        -121.750000   \n",
              "25%                        -2.670000                          25.130000   \n",
              "50%                        -0.820000                          47.440000   \n",
              "75%                         2.590000                          80.500000   \n",
              "max                         9.150000                         161.430000   \n",
              "\n",
              "       Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                       133.000000                        133.000000  \n",
              "mean                         85.706692                         -4.252331  \n",
              "std                         154.329176                          4.032660  \n",
              "min                        -309.450000                        -15.900000  \n",
              "25%                         -43.600000                         -6.670000  \n",
              "50%                          69.530000                         -3.300000  \n",
              "75%                         235.400000                         -2.190000  \n",
              "max                         416.300000                          3.100000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4203e506-8388-4dae-a628-fd21c048efca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>133.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>133.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.037594</td>\n",
              "      <td>9.773372</td>\n",
              "      <td>2.377970</td>\n",
              "      <td>0.123684</td>\n",
              "      <td>50.458346</td>\n",
              "      <td>85.706692</td>\n",
              "      <td>-4.252331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.750448</td>\n",
              "      <td>0.978841</td>\n",
              "      <td>2.453651</td>\n",
              "      <td>3.593634</td>\n",
              "      <td>50.245174</td>\n",
              "      <td>154.329176</td>\n",
              "      <td>4.032660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.381259</td>\n",
              "      <td>-3.550000</td>\n",
              "      <td>-8.670000</td>\n",
              "      <td>-121.750000</td>\n",
              "      <td>-309.450000</td>\n",
              "      <td>-15.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>9.083060</td>\n",
              "      <td>1.060000</td>\n",
              "      <td>-2.670000</td>\n",
              "      <td>25.130000</td>\n",
              "      <td>-43.600000</td>\n",
              "      <td>-6.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.973967</td>\n",
              "      <td>2.190000</td>\n",
              "      <td>-0.820000</td>\n",
              "      <td>47.440000</td>\n",
              "      <td>69.530000</td>\n",
              "      <td>-3.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>10.632882</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>2.590000</td>\n",
              "      <td>80.500000</td>\n",
              "      <td>235.400000</td>\n",
              "      <td>-2.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>11.141502</td>\n",
              "      <td>8.260000</td>\n",
              "      <td>9.150000</td>\n",
              "      <td>161.430000</td>\n",
              "      <td>416.300000</td>\n",
              "      <td>3.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4203e506-8388-4dae-a628-fd21c048efca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4203e506-8388-4dae-a628-fd21c048efca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4203e506-8388-4dae-a628-fd21c048efca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "No_G20_Data = pd.concat([Data1.xs(No_G20[i]) for i in range(len(No_G20))])\n",
        "No_G20_Data.describe()"
      ],
      "metadata": {
        "id": "K6lr1JqlqsKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "50933ff0-0432-4b99-e4de-3674458e7b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating (Num)  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count    739.000000       739.000000       739.000000   \n",
              "mean      10.523681         9.065402         3.241055   \n",
              "std        5.018980         1.318907         3.146899   \n",
              "min        1.000000         6.061294       -10.190000   \n",
              "25%        6.000000         8.169160         1.925000   \n",
              "50%        9.000000         8.962349         3.190000   \n",
              "75%       14.000000        10.066179         4.730000   \n",
              "max       20.000000        11.765265        25.180000   \n",
              "\n",
              "       Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                     739.000000                         739.000000   \n",
              "mean                       -1.173464                          32.497848   \n",
              "std                         9.002442                          69.731575   \n",
              "min                       -47.850000                        -558.870000   \n",
              "25%                        -4.610000                          19.760000   \n",
              "50%                        -1.470000                          37.790000   \n",
              "75%                         2.610000                          61.800000   \n",
              "max                        71.340000                         267.470000   \n",
              "\n",
              "       Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                       739.000000                        739.000000  \n",
              "mean                         53.677794                         -3.143207  \n",
              "std                         125.718418                          4.695415  \n",
              "min                        -682.050000                        -28.500000  \n",
              "25%                           3.475000                         -5.575000  \n",
              "50%                          49.080000                         -3.040000  \n",
              "75%                         115.660000                         -0.610000  \n",
              "max                         533.360000                         21.800000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6516602e-39a5-477f-b60b-2dbfe94cdc37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>739.000000</td>\n",
              "      <td>739.000000</td>\n",
              "      <td>739.000000</td>\n",
              "      <td>739.000000</td>\n",
              "      <td>739.000000</td>\n",
              "      <td>739.000000</td>\n",
              "      <td>739.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.523681</td>\n",
              "      <td>9.065402</td>\n",
              "      <td>3.241055</td>\n",
              "      <td>-1.173464</td>\n",
              "      <td>32.497848</td>\n",
              "      <td>53.677794</td>\n",
              "      <td>-3.143207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.018980</td>\n",
              "      <td>1.318907</td>\n",
              "      <td>3.146899</td>\n",
              "      <td>9.002442</td>\n",
              "      <td>69.731575</td>\n",
              "      <td>125.718418</td>\n",
              "      <td>4.695415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.061294</td>\n",
              "      <td>-10.190000</td>\n",
              "      <td>-47.850000</td>\n",
              "      <td>-558.870000</td>\n",
              "      <td>-682.050000</td>\n",
              "      <td>-28.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.169160</td>\n",
              "      <td>1.925000</td>\n",
              "      <td>-4.610000</td>\n",
              "      <td>19.760000</td>\n",
              "      <td>3.475000</td>\n",
              "      <td>-5.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.962349</td>\n",
              "      <td>3.190000</td>\n",
              "      <td>-1.470000</td>\n",
              "      <td>37.790000</td>\n",
              "      <td>49.080000</td>\n",
              "      <td>-3.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>10.066179</td>\n",
              "      <td>4.730000</td>\n",
              "      <td>2.610000</td>\n",
              "      <td>61.800000</td>\n",
              "      <td>115.660000</td>\n",
              "      <td>-0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>11.765265</td>\n",
              "      <td>25.180000</td>\n",
              "      <td>71.340000</td>\n",
              "      <td>267.470000</td>\n",
              "      <td>533.360000</td>\n",
              "      <td>21.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6516602e-39a5-477f-b60b-2dbfe94cdc37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6516602e-39a5-477f-b60b-2dbfe94cdc37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6516602e-39a5-477f-b60b-2dbfe94cdc37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OECD_Data = pd.concat([Data1.xs(OECD[i]) for i in range(len(OECD))])\n",
        "OECD_Data.describe()"
      ],
      "metadata": {
        "id": "NWo0_EIgRrsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "495bac2f-eb7b-4199-f037-758dae4a1e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating (Num)  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count    266.000000       266.000000       266.000000   \n",
              "mean      16.052632        10.357884         2.937218   \n",
              "std        3.815195         0.683760         2.793144   \n",
              "min        4.000000         8.592471        -0.520000   \n",
              "25%       14.000000         9.818579         1.840000   \n",
              "50%       17.000000        10.567649         2.340000   \n",
              "75%       19.000000        10.857581         3.665000   \n",
              "max       20.000000        11.765265        25.180000   \n",
              "\n",
              "       Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                     266.000000                         266.000000   \n",
              "mean                        1.170301                          46.503872   \n",
              "std                         3.990279                          60.278513   \n",
              "min                       -19.850000                        -281.760000   \n",
              "25%                        -2.030000                          23.360000   \n",
              "50%                         0.810000                          43.310000   \n",
              "75%                         4.057500                          74.817500   \n",
              "max                        10.840000                         187.940000   \n",
              "\n",
              "       Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                       266.000000                        266.000000  \n",
              "mean                        109.552820                         -2.497519  \n",
              "std                         147.582595                          3.554127  \n",
              "min                        -571.910000                        -15.590000  \n",
              "25%                          36.845000                         -4.295000  \n",
              "50%                          77.060000                         -2.105000  \n",
              "75%                         215.370000                         -0.005000  \n",
              "max                         533.360000                          7.870000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-666d0d1b-3dff-4850-b104-c27196a120cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>266.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>266.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16.052632</td>\n",
              "      <td>10.357884</td>\n",
              "      <td>2.937218</td>\n",
              "      <td>1.170301</td>\n",
              "      <td>46.503872</td>\n",
              "      <td>109.552820</td>\n",
              "      <td>-2.497519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.815195</td>\n",
              "      <td>0.683760</td>\n",
              "      <td>2.793144</td>\n",
              "      <td>3.990279</td>\n",
              "      <td>60.278513</td>\n",
              "      <td>147.582595</td>\n",
              "      <td>3.554127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.592471</td>\n",
              "      <td>-0.520000</td>\n",
              "      <td>-19.850000</td>\n",
              "      <td>-281.760000</td>\n",
              "      <td>-571.910000</td>\n",
              "      <td>-15.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.818579</td>\n",
              "      <td>1.840000</td>\n",
              "      <td>-2.030000</td>\n",
              "      <td>23.360000</td>\n",
              "      <td>36.845000</td>\n",
              "      <td>-4.295000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>10.567649</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>43.310000</td>\n",
              "      <td>77.060000</td>\n",
              "      <td>-2.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>10.857581</td>\n",
              "      <td>3.665000</td>\n",
              "      <td>4.057500</td>\n",
              "      <td>74.817500</td>\n",
              "      <td>215.370000</td>\n",
              "      <td>-0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>11.765265</td>\n",
              "      <td>25.180000</td>\n",
              "      <td>10.840000</td>\n",
              "      <td>187.940000</td>\n",
              "      <td>533.360000</td>\n",
              "      <td>7.870000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-666d0d1b-3dff-4850-b104-c27196a120cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-666d0d1b-3dff-4850-b104-c27196a120cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-666d0d1b-3dff-4850-b104-c27196a120cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "No_OECD_Data = pd.concat([Data1.xs(No_OECD[i]) for i in range(len(No_OECD))])\n",
        "No_OECD_Data.describe()"
      ],
      "metadata": {
        "id": "dVs2V1vNR3it",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "9882b9cf-f9ea-4cab-a3ba-4031030615fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating (Num)  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count    606.000000       606.000000       606.000000   \n",
              "mean       8.867987         8.653454         3.185000   \n",
              "std        3.975428         1.154086         3.177468   \n",
              "min        1.000000         6.061294       -10.190000   \n",
              "25%        6.000000         7.877346         1.600000   \n",
              "50%        8.000000         8.623036         3.360000   \n",
              "75%       11.000000         9.482835         5.065000   \n",
              "max       20.000000        11.651459        13.790000   \n",
              "\n",
              "       Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                     606.000000                         606.000000   \n",
              "mean                       -1.917558                          30.291815   \n",
              "std                         9.597069                          69.789050   \n",
              "min                       -47.850000                        -558.870000   \n",
              "25%                        -5.445000                          18.920000   \n",
              "50%                        -2.405000                          37.970000   \n",
              "75%                         1.545000                          60.995000   \n",
              "max                        71.340000                         267.470000   \n",
              "\n",
              "       Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                       606.000000                        606.000000  \n",
              "mean                         36.181238                         -3.670050  \n",
              "std                         116.112585                          4.971711  \n",
              "min                        -682.050000                        -28.500000  \n",
              "25%                         -19.147500                         -6.387500  \n",
              "50%                          36.550000                         -3.635000  \n",
              "75%                         102.602500                         -1.477500  \n",
              "max                         401.330000                         21.800000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ad2dff3-dd01-4cbe-9f67-8592ead6d85f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.867987</td>\n",
              "      <td>8.653454</td>\n",
              "      <td>3.185000</td>\n",
              "      <td>-1.917558</td>\n",
              "      <td>30.291815</td>\n",
              "      <td>36.181238</td>\n",
              "      <td>-3.670050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.975428</td>\n",
              "      <td>1.154086</td>\n",
              "      <td>3.177468</td>\n",
              "      <td>9.597069</td>\n",
              "      <td>69.789050</td>\n",
              "      <td>116.112585</td>\n",
              "      <td>4.971711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.061294</td>\n",
              "      <td>-10.190000</td>\n",
              "      <td>-47.850000</td>\n",
              "      <td>-558.870000</td>\n",
              "      <td>-682.050000</td>\n",
              "      <td>-28.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.877346</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>-5.445000</td>\n",
              "      <td>18.920000</td>\n",
              "      <td>-19.147500</td>\n",
              "      <td>-6.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.623036</td>\n",
              "      <td>3.360000</td>\n",
              "      <td>-2.405000</td>\n",
              "      <td>37.970000</td>\n",
              "      <td>36.550000</td>\n",
              "      <td>-3.635000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>9.482835</td>\n",
              "      <td>5.065000</td>\n",
              "      <td>1.545000</td>\n",
              "      <td>60.995000</td>\n",
              "      <td>102.602500</td>\n",
              "      <td>-1.477500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>11.651459</td>\n",
              "      <td>13.790000</td>\n",
              "      <td>71.340000</td>\n",
              "      <td>267.470000</td>\n",
              "      <td>401.330000</td>\n",
              "      <td>21.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ad2dff3-dd01-4cbe-9f67-8592ead6d85f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ad2dff3-dd01-4cbe-9f67-8592ead6d85f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ad2dff3-dd01-4cbe-9f67-8592ead6d85f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invest_grade = Data1[Data1['Rating (Num)']>10]\n",
        "invest_grade.describe()"
      ],
      "metadata": {
        "id": "uOUjLS7LBJBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "e7ed5340-cf52-4bfc-f161-58e27170a030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating (Num)  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count    443.000000       443.000000       443.000000   \n",
              "mean      15.401806        10.060404         3.040474   \n",
              "std        3.181706         0.893662         2.959306   \n",
              "min       11.000000         7.381259        -6.320000   \n",
              "25%       12.500000         9.529400         1.680000   \n",
              "50%       16.000000        10.155780         2.680000   \n",
              "75%       18.000000        10.747231         4.120000   \n",
              "max       20.000000        11.765265        25.180000   \n",
              "\n",
              "       Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                     443.000000                         443.000000   \n",
              "mean                        1.277449                          19.298849   \n",
              "std                         6.329831                          84.444390   \n",
              "min                       -26.530000                        -558.870000   \n",
              "25%                        -2.130000                           6.505000   \n",
              "50%                         0.840000                          32.570000   \n",
              "75%                         4.570000                          56.555000   \n",
              "max                        24.490000                         161.430000   \n",
              "\n",
              "       Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                       443.000000                        443.000000  \n",
              "mean                         31.961986                         -2.349549  \n",
              "std                         155.981868                          4.874059  \n",
              "min                        -682.050000                        -17.540000  \n",
              "25%                         -48.485000                         -4.410000  \n",
              "50%                          29.490000                         -2.350000  \n",
              "75%                         108.145000                          0.105000  \n",
              "max                         416.300000                         21.800000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d70df51b-80ad-4338-a8bf-085fa9da7f5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>443.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>443.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>15.401806</td>\n",
              "      <td>10.060404</td>\n",
              "      <td>3.040474</td>\n",
              "      <td>1.277449</td>\n",
              "      <td>19.298849</td>\n",
              "      <td>31.961986</td>\n",
              "      <td>-2.349549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.181706</td>\n",
              "      <td>0.893662</td>\n",
              "      <td>2.959306</td>\n",
              "      <td>6.329831</td>\n",
              "      <td>84.444390</td>\n",
              "      <td>155.981868</td>\n",
              "      <td>4.874059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>7.381259</td>\n",
              "      <td>-6.320000</td>\n",
              "      <td>-26.530000</td>\n",
              "      <td>-558.870000</td>\n",
              "      <td>-682.050000</td>\n",
              "      <td>-17.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.500000</td>\n",
              "      <td>9.529400</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>-2.130000</td>\n",
              "      <td>6.505000</td>\n",
              "      <td>-48.485000</td>\n",
              "      <td>-4.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>10.155780</td>\n",
              "      <td>2.680000</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>32.570000</td>\n",
              "      <td>29.490000</td>\n",
              "      <td>-2.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>10.747231</td>\n",
              "      <td>4.120000</td>\n",
              "      <td>4.570000</td>\n",
              "      <td>56.555000</td>\n",
              "      <td>108.145000</td>\n",
              "      <td>0.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>11.765265</td>\n",
              "      <td>25.180000</td>\n",
              "      <td>24.490000</td>\n",
              "      <td>161.430000</td>\n",
              "      <td>416.300000</td>\n",
              "      <td>21.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d70df51b-80ad-4338-a8bf-085fa9da7f5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d70df51b-80ad-4338-a8bf-085fa9da7f5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d70df51b-80ad-4338-a8bf-085fa9da7f5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_invest_grade = Data1[Data1['Rating (Num)']<=10]\n",
        "non_invest_grade.describe()"
      ],
      "metadata": {
        "id": "BRDSZKZ4Azws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "4fc316d2-22dc-4946-de68-0107c4afb394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating (Num)  log(GDP/Capita)  Real GDP Growth  \\\n",
              "count    429.000000       429.000000       429.000000   \n",
              "mean       6.575758         8.257416         3.180606   \n",
              "std        1.877553         0.973060         3.174063   \n",
              "min        1.000000         6.061294       -10.190000   \n",
              "25%        5.000000         7.582392         1.790000   \n",
              "50%        7.000000         8.313127         3.410000   \n",
              "75%        8.000000         8.829209         5.030000   \n",
              "max       10.000000        10.428199        13.790000   \n",
              "\n",
              "       Current Account Balance / GDP  Net General Government Debt / GDP  \\\n",
              "count                     429.000000                         429.000000   \n",
              "mean                       -3.302214                          51.695758   \n",
              "std                         9.597538                          36.734082   \n",
              "min                       -47.850000                         -68.890000   \n",
              "25%                        -6.260000                          29.390000   \n",
              "50%                        -3.170000                          45.340000   \n",
              "75%                        -0.610000                          69.500000   \n",
              "max                        71.340000                         267.470000   \n",
              "\n",
              "       Narrow Net External Debt / CARs  General Government Balance / GDP  \n",
              "count                       429.000000                        429.000000  \n",
              "mean                         86.031981                         -4.306620  \n",
              "std                          90.849213                          4.107439  \n",
              "min                        -152.010000                        -28.500000  \n",
              "25%                          25.590000                         -6.520000  \n",
              "50%                          78.940000                         -4.040000  \n",
              "75%                         122.740000                         -1.930000  \n",
              "max                         533.360000                         10.830000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be7c4210-a7db-4624-a410-801e281ffa80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating (Num)</th>\n",
              "      <th>log(GDP/Capita)</th>\n",
              "      <th>Real GDP Growth</th>\n",
              "      <th>Current Account Balance / GDP</th>\n",
              "      <th>Net General Government Debt / GDP</th>\n",
              "      <th>Narrow Net External Debt / CARs</th>\n",
              "      <th>General Government Balance / GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>429.000000</td>\n",
              "      <td>429.000000</td>\n",
              "      <td>429.000000</td>\n",
              "      <td>429.000000</td>\n",
              "      <td>429.000000</td>\n",
              "      <td>429.000000</td>\n",
              "      <td>429.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.575758</td>\n",
              "      <td>8.257416</td>\n",
              "      <td>3.180606</td>\n",
              "      <td>-3.302214</td>\n",
              "      <td>51.695758</td>\n",
              "      <td>86.031981</td>\n",
              "      <td>-4.306620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.877553</td>\n",
              "      <td>0.973060</td>\n",
              "      <td>3.174063</td>\n",
              "      <td>9.597538</td>\n",
              "      <td>36.734082</td>\n",
              "      <td>90.849213</td>\n",
              "      <td>4.107439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.061294</td>\n",
              "      <td>-10.190000</td>\n",
              "      <td>-47.850000</td>\n",
              "      <td>-68.890000</td>\n",
              "      <td>-152.010000</td>\n",
              "      <td>-28.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.582392</td>\n",
              "      <td>1.790000</td>\n",
              "      <td>-6.260000</td>\n",
              "      <td>29.390000</td>\n",
              "      <td>25.590000</td>\n",
              "      <td>-6.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.313127</td>\n",
              "      <td>3.410000</td>\n",
              "      <td>-3.170000</td>\n",
              "      <td>45.340000</td>\n",
              "      <td>78.940000</td>\n",
              "      <td>-4.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.829209</td>\n",
              "      <td>5.030000</td>\n",
              "      <td>-0.610000</td>\n",
              "      <td>69.500000</td>\n",
              "      <td>122.740000</td>\n",
              "      <td>-1.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.428199</td>\n",
              "      <td>13.790000</td>\n",
              "      <td>71.340000</td>\n",
              "      <td>267.470000</td>\n",
              "      <td>533.360000</td>\n",
              "      <td>10.830000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be7c4210-a7db-4624-a410-801e281ffa80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be7c4210-a7db-4624-a410-801e281ffa80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be7c4210-a7db-4624-a410-801e281ffa80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SaV18SHPfqGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code from Github"
      ],
      "metadata": {
        "id": "4_oAp-PT3Cmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We* use this code [Git link](https://github.com/sagyome/XGBoostTreeApproximator) which apply the ideas from this [paper](https://pdf.sciencedirectassets.com/271625/1-s2.0-S0020025521X00187/1-s2.0-S0020025521005272/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGsaCXVzLWVhc3QtMSJGMEQCIF6teoIE2nGXP56x03iO8zXBr%2BsGuj52vvYeSj4izKesAiBX1GjgCSnfsZCgdPk8LPU22Td07Ro%2Fr%2F%2Bnt2dV0a0OHyqDBAjz%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDA1OTAwMzU0Njg2NSIMB0D3isn08XmEFKOPKtcDEvaylB25%2B4t%2FQtfZtTLdqkC4Sf4DKOPzgdzKRF7eXTGUyjbVbgszPCi6H2K0SnCr3ocwACaSWORK8UAEq%2BuaNCVlLZERgaMWf%2FpTzSbCGQ88HQ9%2B0QKVOiNyCZBhH%2Bt2wsHTdbYEqCTKKQsTqZQalS5t9v1knT%2FvhRNCPvuIsZHQDpvKpZAuBq44cyGPuJzWfpndCreXkRk1cF6rqWUe7qdyoqsaWmW%2FBBrv6HHg0Y3Cl8910dIL5NLTohI4jD7n9YBoiqZ%2B9zj9%2Bo2zKuyIH8DBR%2BitF%2Bx2im63wkrzjTGQP3i3saRgSsvqJzYG1T6pZvythIhE0seYwJTMFFIj1Wjoc5Psc2x5UYxB4BrJ%2Fv89ORaf2tYHSTnohpusJqCMpcizDeJ6OAs4uTbhqQFZagEdcxqbK0frnayzpv6AxhFDBgfUn55uqujrnsIYoto9R3zJex1ZRRu4K65MzkIW6NM%2BGwoFQeLCbk4LeEGTEWcRhLCP%2B%2FerGX4tUx11Oz%2F8no6RdNqlpujE5kVTFlEJpTJjwiOCyDrfW0bP3HFquyKCUdRW5wg5RdB7GyO3QZlwtYP1ySkFPNlsWtnXZp4i9wQ3kBzjACB5dWwcfXyYTLrbySKrzAz5MO68kpIGOqYBkg2eujRO95WMZHPzG7xFxkC0J60JVgljiIQCp27WIcD2vW9EJ9QWda8u4GtyK%2Bi4BqeAABzw1AdC5BFSMXpZi%2FVqJz8H94WIVXei5WiRdXLpr16tmzzTgK5DmJgWnfsEAZgPAjXhwK%2BAkY47v2s%2BifPlHK%2FUb88WEDAKK64ymJ9ejQaNycGqdePhhj3rF3WVhkhZRXiWR%2Fdwjh6cZsPucI47yBS0TA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220330T184104Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYYSBAZ4P5%2F20220330%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=397f5cf7069ee7493c39f2de47fba706d265f9e2342f2f2ae33efffbe99fdd8a&hash=e16aaf61b7d8706e70fb9717b7de4a29c3526a2cc21a6f61e91e2f5dd79bb889&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0020025521005272&tid=spdf-2e05318e-55ff-45df-b9a9-097116e8134c&sid=5b01b6dc45b3d242147a4c7-03d301b7febagxrqb&type=client&download=true&ua=4c00505103075600075f54&rr=6f42fa2ef86c5a37)"
      ],
      "metadata": {
        "id": "4YZY4Yr43Pcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets"
      ],
      "metadata": {
        "id": "EV12o0yFRFER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Read datasets\n",
        "This script contain all the functions that enable reading datasets for experiments\n",
        "Each get_xxx function returns train set, test set, names of the feature columns and label column.\n",
        "Some of the datasets available from sklearn while others are read from files that are stored in \\datasets\n",
        "In some cases required data cleansing and processing is conducted\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_diabetes, load_wine\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "import calendar\n",
        "month_dict = dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
        "day_dict = dict((v,k) for k,v in enumerate(calendar.day_name))\n",
        "\n",
        "def get_sklearn_ds(data,train_test_ratio):\n",
        "    \"\"\"\n",
        "    This function read, split and process datasets that come from sklearn\n",
        "    :param data: sklearn.utils.Bunch object that rperesents the dataset\n",
        "    :param train_test_ratio: The proportion on training instances\n",
        "    :return: train data and test data (pandas dataframes), names of feature columns and label column\n",
        "    \"\"\"\n",
        "    feature_cols, label_col = data.feature_names, 'class'\n",
        "    X, y = data.data, data.target\n",
        "    data = pd.DataFrame(X, columns=data.feature_names)\n",
        "    data['class'] = y\n",
        "    train = data.sample(frac=train_test_ratio)\n",
        "    test = data.drop(train.index)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def dummify_data(data,feature_cols, label_col):\n",
        "    \"\"\"\n",
        "    This function identify categorical features and convert them into multiple binary features (one for each category)\n",
        "    :param data: pandas dataframe\n",
        "    :param feature_cols: feature names\n",
        "    :param label_col: label column name\n",
        "    :return: pandas dataframe with dummy features, names of the new features\n",
        "    \"\"\"\n",
        "\n",
        "    #The following line identifies the categorical features in the dataset\n",
        "    char_cols = data[feature_cols].dtypes.pipe(lambda x: x[x == 'object']).index\n",
        "\n",
        "    #convert the categorical features to multiple dummy variables and add them to the dataframe\n",
        "    for col in char_cols:\n",
        "        dummies = pd.get_dummies(data[col])\n",
        "        dummies.columns = [col + '=' + category for category in dummies.columns]\n",
        "        data = pd.concat([data, dummies], axis=1)\n",
        "\n",
        "    #Remove the original categorical features from the dataframe\n",
        "    data = data.drop(char_cols,axis=1)\n",
        "    feature_cols = [col for col in data.columns if col != label_col]\n",
        "    return data, feature_cols\n",
        "\n",
        "def data_processing(data,train_test_ratio,label_col,random_state):\n",
        "    \"\"\"\n",
        "    This function changes the label names as enumerates and divide data to train-test\n",
        "    :param data: pandas dataframe\n",
        "    :param train_test_ratio: proportion of training data\n",
        "    :param label_col: label column name\n",
        "    :return: train and test sets as pandas dataframes\n",
        "    \"\"\"\n",
        "    labels_dict = {v: k for k, v in enumerate(data[label_col].unique())}\n",
        "    data[label_col] = [labels_dict[i] for i in data[label_col]]\n",
        "    train = data.sample(frac=train_test_ratio,random_state=random_state)\n",
        "    test = data.drop(train.index)\n",
        "    return train, test\n",
        "\n",
        "def get_iris_data(random_state, train_test_ratio=0.8):\n",
        "    return get_sklearn_ds(load_iris(),train_test_ratio)\n",
        "\n",
        "def get_breast_cancer_data(random_state, train_test_ratio=0.8):\n",
        "    return get_sklearn_ds(load_breast_cancer(), train_test_ratio)\n",
        "\n",
        "def get_winery_data(random_state, train_test_ratio=0.8):\n",
        "    train, test, feature_cols, label_col = get_sklearn_ds(load_wine(), train_test_ratio)\n",
        "    train['magnesium'], test['magnesium'] = train['magnesium'].astype(int), test['magnesium'].astype(int)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_diabetes(random_state, train_test_ratio=0.8):\n",
        "    return get_sklearn_ds(load_diabetes(),train_test_ratio)\n",
        "\n",
        "def get_kohkilyeh(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/kohkiloyeh.csv')\n",
        "    label_col = 'pb'\n",
        "    data,feature_cols = dummify_data(data,data.columns[:-1],label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_haberman(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['Age', 'year_of_operation', 'number_of_positive_axiilary_nodes']\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/haberman.data',names= feature_cols+[label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "\n",
        "def get_balance_scale(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['left-weight', 'left-dist', 'right-weight', 'right-dist']\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/balance-scale.data', names=[label_col]+feature_cols)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_spambase(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = []\n",
        "    with open('datasets/spambase.names', 'r') as f:\n",
        "        for line in f:\n",
        "            feature_cols.append(line.replace('\\n', '').replace(']','xxx').replace('[','xxx'))\n",
        "    label_col = 'is_spam'\n",
        "    data = pd.read_csv('datasets/spambase.data', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_zoo(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(17)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/zoo.data', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols[1:], label_col\n",
        "\n",
        "def get_german(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x'+str(i) for i in range(20)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/german.data',sep=' ', names = feature_cols+[label_col])\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    for col in data.columns:\n",
        "        data[col] = data[col].astype(int)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_pima(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x'+str(i) for i in range(8)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/pima.scv', names=feature_cols+[label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_bank(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/bank.txt', sep=';')\n",
        "    label_col = 'y'\n",
        "    data, feature_cols = dummify_data(data, data.columns[:-1], label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_banknote(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(4)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/banknote.txt', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_car(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(6)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/car.data', names=feature_cols + [label_col])\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_credit(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(15)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/credit.data', names=feature_cols + [label_col])\n",
        "    for col in ['x1','x2','x7','x13']:\n",
        "        data[col] = data[col].replace('?', -1000).astype(float).values\n",
        "        data = data[data[col] > -1000]\n",
        "    data = data[data['class'].apply(lambda x: isinstance(x, str))]\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_ctherapy(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/cryotherapy.csv')\n",
        "    data = data.rename({'Result_of_Treatment':'class'},axis=1)\n",
        "    label_col = 'class'\n",
        "    feature_cols = data.columns[:-1]\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_internet_trust(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(4)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/disshonest_internet.txt.txt', names=feature_cols+ [label_col], sep=' ')\n",
        "    data,feature_cols = dummify_data(data,feature_cols,label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_forest(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/forsttypes.csv')\n",
        "    feature_cols = data.columns[1:]\n",
        "    label_col = 'class'\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_glass(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x'+str(i) for i in range(10)][1:]\n",
        "    label_col='class'\n",
        "    data = pd.read_csv('datasets/glass.data',names=feature_cols+[label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_liver(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(10)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/liver.csv', names=feature_cols+ [label_col]).dropna()\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_vegas(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/LasVegasTripAdvisorReviews-Dataset.csv', sep=';')\n",
        "    data = data.rename({'Score': 'class'}, axis=1)\n",
        "    data = data.drop(['User country', 'Hotel name'], axis=1)\n",
        "    data['Hotel stars'] = data['Hotel stars'].apply(lambda x: float(x.replace(',', '.')))\n",
        "    data['Review month'] = data['Review month'].apply(lambda x: month_dict[x[:3]])\n",
        "    data['Review weekday'] = data['Review weekday'].apply(lambda x: day_dict[x])\n",
        "    label_col = 'class'\n",
        "    feature_cols = [col for col in data.columns if col != 'class']\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_magic(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(10)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/magic04.data', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_mamo(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(5)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/mammographic_masses.data', names=feature_cols + [label_col])\n",
        "    data = data[['?' not in str(row) for indx, row in data.iterrows()]]\n",
        "    for col in feature_cols:\n",
        "        data[col] = data[col].astype(int)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_occupancy(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/occupancy.txt')\n",
        "    data = data.drop(['date'], axis=1)\n",
        "    data = data.rename({'Occupancy': 'class'},axis=1)\n",
        "    feature_cols = data.columns[:-1]\n",
        "    label_col = 'class'\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_biodeg(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(41)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/biodeg.txt', sep=';', names=feature_cols+ [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_seismic(random_state, train_test_ratio=.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(18)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/seismic.arff', names=feature_cols + [label_col])\n",
        "    data, feature_cols = dummify_data(data,feature_cols,label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_abalone(random_state, train_test_ratio=.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(8)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/abalone.data', names=feature_cols + [label_col])\n",
        "    data['x0'] = [1 if i == 'M' else 0 for i in data['x0']]\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_ecoli(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x'+str(i) for i in range(8)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/ecoli1.data',names=feature_cols+[label_col])\n",
        "    feature_cols = feature_cols[1:]\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_australian(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = [\"A\" + str(i) for i in range(14)]\n",
        "    label_col ='class'\n",
        "    data = pd.read_csv(\"datasets/australian.dat\", sep=\" \", names=feature_cols+[label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_nurse(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(8)]\n",
        "    label_col ='class'\n",
        "    data = pd.read_csv(\"datasets/post-operative.data\", names = feature_cols + [label_col])\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    data[label_col] = [i[0] for i in data[label_col]]\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_tic_tac_toe(random_state, train_test_ratio=0.8):\n",
        "    feature_cols=['top - left - square','top - middle - square','top - right - square','middle - left - square',\n",
        "               'middle - middle - square','middle - right - square','bottom - left - square','bottom - middle - square','bottom - right - square']\n",
        "    label_col='class'\n",
        "    data=pd.read_csv('datasets/tic-tac-toe.data',names=feature_cols+[label_col])\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_aust_weather_data(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/weatherAUS.csv')\n",
        "    data = data[[k for k, v in data.isnull().sum().sort_values(ascending=False).items() if v < 1000]]\n",
        "    label_col = data.columns[-1]\n",
        "    feature_cols = data.columns[1:-1]\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    data = data.sample(10000)\n",
        "    for k, v in data.isnull().sum().sort_values(ascending=False).items():\n",
        "        if v > 0:\n",
        "            mean_val = data[k].mean()\n",
        "            data[k] = data[k].fillna(mean_val)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "def get_thyroid_data(random_state, train_test_ratio=0.8):\n",
        "    f = open('datasets/allbp.txt', 'r')\n",
        "    records = []\n",
        "    for line in f:\n",
        "        line = line.split('|')[0].split(',')\n",
        "        records.append({i: val for i, val in enumerate(line)})\n",
        "    f.close()\n",
        "    data = pd.DataFrame(records)\n",
        "    numeric_idices = [0, 17, 19, 21, 23, 25]\n",
        "    for indx in numeric_idices:\n",
        "        data[indx] = data[indx].replace('?', np.nan).astype(float)\n",
        "        data[indx] = data[indx].replace(np.nan,data[indx].mean())\n",
        "    data.columns = ['x' + str(col) for col in data.columns[:-1]] + ['class']\n",
        "    feature_cols = data.columns[:-1]\n",
        "    label_col = data.columns[-1]\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    train, test = train[train[label_col] < 2], test[test[label_col] < 2]\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_shuttle_data(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/shuttle.txt', sep=' ', names=['x' + str(i) for i in range(9)] + ['class'])\n",
        "    data = data[data['class'].isin([1, 4, 5])]\n",
        "    feature_cols = data.columns[:-1]\n",
        "    label_col = data.columns[-1]\n",
        "    data, feature_cols = dummify_data(data, feature_cols, label_col)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_seeds_data(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(7)]\n",
        "    label_col = 'class'\n",
        "    f = open('datasets/seeds_dataset.txt', 'r')\n",
        "    records = []\n",
        "    for line in f:\n",
        "        d = []\n",
        "        record = line.split('\\t')\n",
        "        for item in record:\n",
        "            try:\n",
        "                item = float(item)\n",
        "                d.append(item)\n",
        "            except:\n",
        "                continue\n",
        "        records.append(d)\n",
        "    data = pd.DataFrame(records)\n",
        "    data.columns = ['x' + str(i) for i in data.columns[:-1]] + ['class']\n",
        "    data['class'] = data['class'].astype(int)\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_contraceptive_data(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(9)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/cmc.txt', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_cardiotocography_data(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/cardiotocography.csv')\n",
        "    label_col = 'NSP'\n",
        "    feature_cols = data.columns[:-1]\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_ionosphere_data(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(34)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/ionosphere.data', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_hayes_roth_dataset(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(5)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/hayes-roth.data', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_waveform_data(random_state, train_test_ratio=0.8):\n",
        "    feature_cols = ['x' + str(i) for i in range(21)]\n",
        "    label_col = 'class'\n",
        "    data = pd.read_csv('datasets/waveform.data', names=feature_cols + [label_col])\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "\n",
        "def get_divorce_data(random_state, train_test_ratio=0.8):\n",
        "    data = pd.read_csv('datasets/divorce.csv',sep=';')\n",
        "    feature_cols = data.columns[:-1]\n",
        "    label_col = data.columns[-1]\n",
        "    train, test = data_processing(data, train_test_ratio, label_col,random_state)\n",
        "    return train, test, feature_cols, label_col\n",
        "#def get_happiness_data(random_state, train_test_ratio=0.8):\n",
        "\n",
        "\n",
        "datasets_dict = {'iris':get_iris_data,'breast_cancer':get_breast_cancer_data,\n",
        "                 'winery':get_winery_data ,'kohkiloyeh':get_kohkilyeh,'thyroid':get_thyroid_data,\n",
        "                 'haberman':get_haberman,'balance_scale':get_balance_scale,'cardiotocography':get_cardiotocography_data,\n",
        "                 'spambase':get_spambase,'zoo':get_zoo, 'german':get_german,'bank':get_bank,'ionosphere':get_ionosphere_data,\n",
        "                 'banknote':get_banknote,'car':get_car,'credit':get_credit,'ctherapy':get_ctherapy, 'internet':get_internet_trust,'shuttle':get_shuttle_data,\n",
        "                 'forest':get_forest,'glass':get_glass,'liver':get_liver,'vegas':get_vegas, 'magic':get_magic,'mamographic':get_mamo,\n",
        "                 'hayes_roth':get_hayes_roth_dataset, 'waveform':get_waveform_data, 'divorce':get_divorce_data,\n",
        "                 'occupancy':get_occupancy,'biodeg':get_biodeg,'seismic':get_seismic,'ecoli':get_ecoli,'contraceptive':get_contraceptive_data,\n",
        "                 'aust':get_australian,'nurse':get_nurse,'tic_tac_toe':get_tic_tac_toe, 'abalone':get_abalone,'pima':get_pima, 'seeds':get_seeds_data}"
      ],
      "metadata": {
        "id": "DzidCw3vRFOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utils"
      ],
      "metadata": {
        "id": "ObOEPJEFJdKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contains several functions that are used in various stages of the process\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import xgboost as xg\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "\n",
        "RANDOM_SEED = 1\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    This function is useful for converting the aggregated results come from the different trees into class probabilities\n",
        "    :param x: Numpy k-dimensional array\n",
        "    :return: Softmax of X\n",
        "    \"\"\"\n",
        "    return np.array([np.exp(x)/np.sum(np.exp(x))])\n",
        "\n",
        "def get_auc(test_y,y_score):\n",
        "    \"\"\"\n",
        "    :param test_y: Labels\n",
        "    :param y_score: probabilities of labels\n",
        "    :return: ROC AUC score\n",
        "    \"\"\"\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    classes=[i for i in range(y_score.shape[1])]\n",
        "    y_test_binarize=np.array([[1 if i ==c else 0 for c in classes] for i in test_y])\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarize.ravel(), y_score.ravel())\n",
        "    return auc(fpr, tpr)\n",
        "\n",
        "def train_decision_tree(train,feature_cols,label_col):\n",
        "    \"\"\"\n",
        "    This function gets a dataframe as an input and optimizes a decision tree to the data\n",
        "    :param train: Pandas dataframe\n",
        "    :param feature_cols: feature column names\n",
        "    :param label_col: label column name\n",
        "    :return: Trained sklearn decision tree\n",
        "    \"\"\"\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    parameters = {'criterion': ['entropy', 'gini'],\n",
        "                  'max_depth': [3, 5, 10, 20, 50],\n",
        "                  'min_samples_leaf': [1, 2, 5, 10]}\n",
        "    model = DecisionTreeClassifier()\n",
        "    clfGS = GridSearchCV(model, parameters, cv=3)\n",
        "    clfGS.fit(train[feature_cols].values, train[label_col])\n",
        "    return clfGS.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "def train_rf_model(train,feature_cols,label_col):\n",
        "    \"\"\"\n",
        "        This function gets a dataframe as an input and optimizes a random forest classifier to the data\n",
        "        :param train: Pandas dataframe\n",
        "        :param feature_cols: feature column names\n",
        "        :param label_col: label column name\n",
        "        :return: Trained random forest classifier\n",
        "        \"\"\"\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    parameters = {'n_estimators':[50,100],\n",
        "                  'criterion': ['entropy'],\n",
        "                  'min_samples_leaf': [1, 10, 100],\n",
        "                  'max_features':['auto','log2']}\n",
        "    model = RandomForestClassifier()\n",
        "    clfGS = GridSearchCV(model, parameters, cv=3)\n",
        "    clfGS.fit(train[feature_cols].values, train[label_col])\n",
        "    return clfGS.best_estimator_\n",
        "\n",
        "def train_xgb_classifier(train,feature_cols,label_col,xgb_params):\n",
        "    \"\"\"\n",
        "    Train an XGBoost to the input dataframe\n",
        "    :param train: pandas dataframe\n",
        "    :param feature_cols: feature column names\n",
        "    :param label_col: label column name\n",
        "    :param xgb_params: Dict of XGBoost parameters\n",
        "    :return: label column namened XGboost\n",
        "    \"\"\"\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    tuning_params = {'colsample_bytree': [0.3,0.5,0.9],\n",
        "                  'learning_rate': [0.01,0.1],\n",
        "                  'max_depth': [2,5,10],\n",
        "                  'alpha': [1,10],\n",
        "                     'n_estimators':[50,100]}\n",
        "    if train[label_col].nunique() > 2:\n",
        "        xgb_params['objective'] = \"multi:softprob\"\n",
        "    else:\n",
        "        xgb_params['objective'] = \"binary:logitraw\"\n",
        "    model = xg.XGBClassifier(xgb_params)\n",
        "    clfGS = GridSearchCV(model, tuning_params, cv=3)\n",
        "    clfGS.fit(train[feature_cols], train[label_col])\n",
        "    return clfGS.best_estimator_\n",
        "\n",
        "def decision_tree_instance_depth(inst, dt):\n",
        "    \"\"\"\n",
        "    :param inst: Instance to be inferenced - numpy vector\n",
        "    :param dt: sklearn decision tree\n",
        "    :return: The depth of the leaf that corresponds the instance\n",
        "    \"\"\"\n",
        "    indx = 0\n",
        "    depth = 0\n",
        "    # epsilon: thresholds may be shifted by a very small floating points. For example: x1 <= 2.6 may become x1 <= 2.5999999\n",
        "    # and then x1 = 2.6 won't be captured\n",
        "    epsilon = 0.0000001\n",
        "    t = dt.tree_\n",
        "    while t.feature[indx] >= 0:\n",
        "        if inst[t.feature[indx]] <= t.threshold[indx] + epsilon:\n",
        "            indx = t.children_left[indx]\n",
        "        else:\n",
        "            indx = t.children_right[indx]\n",
        "        depth += 1\n",
        "    return  depth\n",
        "\n",
        "def decision_tree_depths(test,feature_cols,dt):\n",
        "    \"\"\"\n",
        "    This function is used for calculatingg the prediction depths of each instance that were inferenced by the input\n",
        "    decision tree\n",
        "    :param test: Pandas dataframe\n",
        "    :param feature_cols: feature column names\n",
        "    :param dt: decision tree\n",
        "    :return: the depths of leaves that were assigned to each instance\n",
        "    \"\"\"\n",
        "    X = test[feature_cols].values\n",
        "    return [decision_tree_instance_depth(inst,dt) for inst in X]\n",
        "\n",
        "#The following are not used:\n",
        "\n",
        "def train_xgb_classifier2(train,feature_cols,label_col,xgb_params):\n",
        "    \"\"\"\n",
        "    Train an XGBoost to the input dataframe\n",
        "    :param train: pandas dataframe\n",
        "    :param feature_cols: feature column names\n",
        "    :param label_col: label column name\n",
        "    :param xgb_params: Dict of XGBoost parameters\n",
        "    :return: label column namened XGboost\n",
        "    \"\"\"\n",
        "    if train[label_col].nunique() > 2:\n",
        "        obj = \"multi:softprob\"\n",
        "    else:\n",
        "        obj = \"binary:logitraw\"\n",
        "    xgb_model = xg.XGBClassifier(**xgb_params)\n",
        "    xgb_model.fit(train[feature_cols], train[label_col])\n",
        "    return  xgb_model\n",
        "\n",
        "def ensemble_prediction_depth(X, rf):\n",
        "    depths = []\n",
        "    for inst in X:\n",
        "        depths.append(np.sum([tree_prediction_depth(inst,base_model.tree_) for base_model in rf.estimators_]))\n",
        "    return depths\n",
        "\n",
        "def tree_prediction_depth(inst, t):\n",
        "    indx = 0\n",
        "    depth = 0\n",
        "    epsilon = 0.0000001\n",
        "    # epsilon: thresholds may be shifted by a very small floating points. For example: x1 <= 2.6 may become x1 <= 2.5999999\n",
        "    # and then x1 = 2.6 won't be captured\n",
        "    while t.feature[indx] >= 0:\n",
        "        if inst[t.feature[indx]] <= t.threshold[indx] + epsilon:\n",
        "            indx = t.children_left[indx]\n",
        "        else:\n",
        "            indx = t.children_right[indx]\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "def get_features_statistics(data):\n",
        "    min_values = {col:min(data[col]) for col in data.columns}\n",
        "    max_values = {col: max(data[col]) for col in data.columns}\n",
        "    mean_values = {col: np.mean(data[col]) for col in data.columns}\n",
        "    return min_values, max_values, mean_values"
      ],
      "metadata": {
        "id": "1JP0KJLC3GJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree"
      ],
      "metadata": {
        "id": "1Ba98VTWJftA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contain a tree class and several functions that are used for constructing the decision tree (stage 2 of the FBT algorithm)\n",
        "\"\"\"\n",
        "\n",
        "from scipy.stats import entropy\n",
        "\n",
        "class Tree():\n",
        "    \"\"\"\n",
        "    A decision tree that is based on hierarchical ordering of conjunction set\n",
        "    Essentialy, the tree is a node with 2 descendents in case of an internal node and a prediction vector if its a leaf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,conjunctions, splitting_values,max_depth):\n",
        "        \"\"\"\n",
        "        :param conjunctions: A list of conjunctions\n",
        "        :param splitting_values: A dictionary in ehich keys are features and values are splitting values ordered by frequency\n",
        "        :param max_depth: Tree maximum depth\n",
        "        \"\"\"\n",
        "\n",
        "        self.conjunctions = conjunctions\n",
        "        self.splitting_values = splitting_values\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def split(self):\n",
        "        # 1. Spliting is stopped if:\n",
        "        #    a. there's a single conjunctions\n",
        "        #    b. Entropy doesn't improved\n",
        "        # 2. Splitting values - at each iteration we selrct the most common value for each feature and selects\n",
        "        #    The one with the highest information gain\n",
        "        # 3. Information gain is calculated as the mean emtropy across the different feature dimensions\n",
        "        if len(self.conjunctions) == 1 or self.max_depth == 0:\n",
        "            self.selected_feature = None\n",
        "            self.left = None\n",
        "            self.right = None\n",
        "            return\n",
        "        if len(set([np.argmax(conj.label_probas) for conj in self.conjunctions])) > 1:\n",
        "            self.selected_feature, self.selected_value, self.entropy, \\\n",
        "            l_conjunctions, r_conjunctions = select_splitting_feature_by_entropy(self.conjunctions, self.splitting_values)\n",
        "        else:\n",
        "            self.selected_feature, self.selected_value, self.entropy, \\\n",
        "            l_conjunctions, r_conjunctions = select_splitting_feature_by_max_splitting(self.conjunctions,\n",
        "                                                                                 self.splitting_values)\n",
        "        if self.selected_feature is None:\n",
        "            return\n",
        "        descending_splitting_values = {k:([i for i in v if i!=self.selected_value] if k == self.selected_feature else v) for k,v in self.splitting_values.items()}\n",
        "        self.left = Tree(l_conjunctions,descending_splitting_values,max_depth = self.max_depth-1)\n",
        "        self.right = Tree(r_conjunctions, descending_splitting_values,max_depth = self.max_depth-1)\n",
        "        self.left.split()\n",
        "        self.right.split()\n",
        "\n",
        "    def predict_instance_proba(self,inst):\n",
        "        \"\"\"\n",
        "        Predicte class probabilities for a given instance\n",
        "        :param inst: Numpy array. Each dimension is a feature\n",
        "        :return: class probabilities\n",
        "        This is a recursive method that routes the instance to its relevant leaf\n",
        "        \"\"\"\n",
        "        if self.selected_feature == None:\n",
        "            #return softmax(np.array([c.label_probas for c in self.conjunctions]).sum(axis=0))\n",
        "            return np.array([softmax(c.label_probas) for c in self.conjunctions]).mean(axis=0)[0]\n",
        "        if inst[self.selected_feature] >= self.selected_value:\n",
        "            return self.left.predict_instance_proba(inst)\n",
        "        else:\n",
        "            return self.right.predict_instance_proba(inst)\n",
        "\n",
        "    def get_instance_decision_path(self, inst,result=[]):\n",
        "        \"\"\"\n",
        "        :param inst: numpy array represents an instance to be inferenced\n",
        "        :param result: a list where each item represents a node\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        result=list(result)\n",
        "        if self.selected_feature == None:\n",
        "            result.append('labels: '+str(np.array([softmax(c.label_probas) for c in self.conjunctions]).mean(axis=0)[0]))\n",
        "            return result\n",
        "        else:\n",
        "            if inst[self.selected_feature] >= self.selected_value:\n",
        "                result.append(str(self.selected_feature)+'>='+str(self.selected_value))\n",
        "                return self.left.get_instance_decision_path(inst,result)\n",
        "            else:\n",
        "                result.append(str(self.selected_feature) + '<' + str(self.selected_value))\n",
        "                return self.right.get_instance_decision_path(inst, result)\n",
        "\n",
        "    def predict_proba(self,data):\n",
        "        \"\"\"\n",
        "        Predicted class probabilities for each data instance\n",
        "        :param data: pandas dataframe\n",
        "        :return: numpy array with calss probabilities for each data instance\n",
        "        \"\"\"\n",
        "        probas=[]\n",
        "        for inst in data.values:\n",
        "            probas.append(self.predict_instance_proba(inst))\n",
        "        return np.array(probas)\n",
        "\n",
        "    def get_decision_paths(self,data):\n",
        "        \"\"\"\n",
        "        :param data: matrix of [numer_of_instances, number_of_features] dimensions\n",
        "        :return: A list where each item corresponds to the decision path of one insance\n",
        "        \"\"\"\n",
        "        paths = []\n",
        "        for inst in data.values:\n",
        "            paths.append(self.get_instance_decision_path(inst))\n",
        "        return paths\n",
        "\n",
        "    # The following methods are relevant for the experimental evaluation. Enable calculating the depth of leaves used for predictions\n",
        "    def predict_proba_and_depth(self,data):\n",
        "        probas = []\n",
        "        depths = []\n",
        "        for inst in data.values:\n",
        "            proba, depth = self.predict_instance_proba_and_depth(inst)\n",
        "            probas.append(proba)\n",
        "            depths.append(depth)\n",
        "        return np.array(probas),depths\n",
        "\n",
        "    def predict_instance_proba_and_depth(self,inst):\n",
        "        if self.selected_feature == None:\n",
        "            #return softmax(np.array([c.label_probas for c in self.conjunctions]).sum(axis=0))\n",
        "            return np.array([softmax(c.label_probas) for c in self.conjunctions]).mean(axis=0)[0], 0\n",
        "        if inst[self.selected_feature] >= self.selected_value:\n",
        "            probas, depth = self.left.predict_instance_proba_and_depth(inst)\n",
        "            return probas, depth + 1\n",
        "        else:\n",
        "            probas, depth = self.right.predict_instance_proba_and_depth(inst)\n",
        "            return probas, depth + 1\n",
        "\n",
        "\n",
        "def select_splitting_feature_by_entropy(conjunctions, splitting_values):\n",
        "    \"\"\"\n",
        "    :param conjunctions: List of conjunctions\n",
        "    :param splitting_values: A dictionary. Keys are features and values are splitting points, ordered by frequency\n",
        "    :return: selected feature, splitting value, weighted entropy stemmed from the split, conjunctions of the left node, conjunctions of the right node\n",
        "    Splitting algorithm:\n",
        "    1. Define the best entropy as the current entropy of the class probability vectors\n",
        "    2. For each feature - get the most frequent spliiting value (first item of the dict) and calculate weighted entropy of split\n",
        "    3. Based on the best entropy - return the derived variables\n",
        "    \"\"\"\n",
        "    conjunctions_len = len(conjunctions)\n",
        "    best_entropy = get_entropy([c.label_probas for c in conjunctions])\n",
        "    selected_feature,selected_value,l_conjunctions, r_conjunctions = None, None, None, None\n",
        "    for feature,values in splitting_values.items():\n",
        "        if len(values)==0:\n",
        "            continue\n",
        "        for i in range(len(values)):#We iterate over all the values within the feature to find the best splitting point\n",
        "            temp_l_conjunctions, temp_r_conjunctions,temp_entropy = calculate_entropy_for_split(conjunctions,feature, values[i])\n",
        "            # We want to prevent a case where all the conjunctions are going to one of the descendent\n",
        "            if temp_entropy < best_entropy and len(temp_l_conjunctions) < conjunctions_len and  len(temp_r_conjunctions) < conjunctions_len:\n",
        "                best_entropy = temp_entropy\n",
        "                selected_feature = feature\n",
        "                selected_value = values[i]\n",
        "                l_conjunctions = temp_l_conjunctions\n",
        "                r_conjunctions = temp_r_conjunctions\n",
        "    return selected_feature,selected_value,best_entropy, l_conjunctions, r_conjunctions\n",
        "\n",
        "def select_splitting_feature_by_max_splitting(conjunctions,splitting_values):\n",
        "    \"\"\"\n",
        "    :param conjunctions: List of conjunctions\n",
        "    :param splitting_values: A dictionary. Keys are features and values are splitting points, ordered by frequency\n",
        "    :return: selected feature, splitting value, weighted entropy stemmed from the split, conjunctions of the left node, conjunctions of the right node\n",
        "    Splitting algorithm:\n",
        "    1. Define the best entropy as the current entropy of the class probability vectors\n",
        "    2. For each feature - get the most frequent spliiting value (first item of the dict) and calculate weighted entropy of split\n",
        "    3. Based on the best entropy - return the derived variables\n",
        "    \"\"\"\n",
        "    conjunctions_len = len(conjunctions)\n",
        "    #best_entropy = get_entropy([c.label_probas for c in conjunctions])\n",
        "    best_value = len(conjunctions)\n",
        "    selected_feature,selected_value,l_conjunctions, r_conjunctions = None, None, None, None\n",
        "    for feature,values in splitting_values.items():\n",
        "        if len(values)==0:\n",
        "            continue\n",
        "        for i in range(len(values)):#We iterate over all the values within the feature to find the best splitting point\n",
        "            temp_l_conjunctions, temp_r_conjunctions, temp_value = calculate_max_for_split(conjunctions, feature, values[i])\n",
        "            if temp_value < best_value:\n",
        "                best_value = temp_value\n",
        "                selected_feature = feature\n",
        "                selected_value = values[i]\n",
        "                l_conjunctions = temp_l_conjunctions\n",
        "                r_conjunctions = temp_r_conjunctions\n",
        "\n",
        "    return selected_feature,selected_value,0, l_conjunctions, r_conjunctions\n",
        "\n",
        "def calculate_entropy_for_split(conjunctions,feature,value):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of splitting the conjunctions according to the given feature vale\n",
        "    :param conjunctions: List of conjunctions\n",
        "    :param feature: splitting feature\n",
        "    :param value: splitting value\n",
        "    :return: conjunctions of left and right nodes, weighted entropy\n",
        "    \"\"\"\n",
        "    l_conjunctions = []\n",
        "    r_conjunctions = []\n",
        "    l_probas = []\n",
        "    r_probas = []\n",
        "    for conj in conjunctions:\n",
        "        if conj.features_upper[feature] <= value:\n",
        "            r_conjunctions.append(conj)\n",
        "            r_probas.append(conj.label_probas)\n",
        "        elif conj.features_lower[feature] >= value:\n",
        "            l_conjunctions.append(conj)\n",
        "            l_probas.append(conj.label_probas)\n",
        "        else:\n",
        "            r_conjunctions.append(conj)\n",
        "            r_probas.append(conj.label_probas)\n",
        "            l_conjunctions.append(conj)\n",
        "            l_probas.append(conj.label_probas)\n",
        "    return l_conjunctions, r_conjunctions, calculate_weighted_entropy(l_probas, r_probas)\n",
        "\n",
        "def calculate_weighted_entropy(l_probas,r_probas):\n",
        "    \"\"\"\n",
        "    :param l_probas: numpy array wehre each item is a probability vector\n",
        "    :param r_probas: numpy array wehre each item is a probability vector\n",
        "    :return: weighted entropy\n",
        "    \"\"\"\n",
        "    l_entropy, r_entropy = get_entropy(l_probas), get_entropy(r_probas)\n",
        "    l_size,r_size = len(l_probas),len(r_probas)\n",
        "    overall_size = l_size+r_size\n",
        "    return(l_size*l_entropy+r_size*r_entropy)/overall_size\n",
        "\n",
        "\n",
        "def get_entropy(probas):\n",
        "    \"\"\"\n",
        "    Calculate antropy of an array of class probability vectors\n",
        "    :param probas: An array of class probability vectors\n",
        "    :return: the average entropy of each class vector\n",
        "    \"\"\"\n",
        "    values = np.array([np.argmax(x) for x in probas])\n",
        "    values, counts = np.unique(values, return_counts=True)\n",
        "    probas = counts / np.sum(counts)\n",
        "    return entropy(probas)\n",
        "\n",
        "def calculate_max_for_split(conjunctions,feature,value):\n",
        "    l_conjunctions = []\n",
        "    r_conjunctions = []\n",
        "    l_probas = []\n",
        "    r_probas = []\n",
        "    for conj in conjunctions:\n",
        "        if conj.features_upper[feature] <= value:\n",
        "            r_conjunctions.append(conj)\n",
        "            r_probas.append(conj.label_probas)\n",
        "        elif conj.features_lower[feature] >= value:\n",
        "            l_conjunctions.append(conj)\n",
        "            l_probas.append(conj.label_probas)\n",
        "        else:\n",
        "            r_conjunctions.append(conj)\n",
        "            r_probas.append(conj.label_probas)\n",
        "            l_conjunctions.append(conj)\n",
        "            l_probas.append(conj.label_probas)\n",
        "    return l_conjunctions, r_conjunctions, max(len(l_conjunctions),len(r_conjunctions))"
      ],
      "metadata": {
        "id": "lrzhxBW5C4_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruning"
      ],
      "metadata": {
        "id": "CDATxA1xJsD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contain the Pruner function for pruning a decision forest\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "class Pruner():\n",
        "    \"\"\"\n",
        "    A static class that supports the pruning of a decision forest\n",
        "    \"\"\"\n",
        "    def predict_probas_tree(self,conjunctions,X):\n",
        "        \"\"\"\n",
        "        Predict probabilities for X using a tree, represented as a conjunction set\n",
        "        :param conjunctions: A list of conjunctions\n",
        "        :param X: numpy array of data instances\n",
        "        :return: class probabilities for each instance of X\n",
        "        \"\"\"\n",
        "\n",
        "        probas = []\n",
        "        for inst in X:\n",
        "            for conj in conjunctions:\n",
        "                if conj.containsInstance(inst):\n",
        "                    probas.append(conj.label_probas)\n",
        "        return np.array(probas)\n",
        "    def predict_probas(self,forest,X):\n",
        "        \"\"\"\n",
        "        Predict probabilities of X, using a decision forest\n",
        "        :param forest: A list of decision trees where each tree is a list of conjunctions\n",
        "        :param X: Numpy array of data instances\n",
        "        :return: List of class probabilities vector\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X.values\n",
        "        for t in forest:\n",
        "            predictions.append(self.predict_probas_tree(t, X))\n",
        "        return np.array([softmax(pred)[0] for pred in np.array(predictions).sum(axis=0)])\n",
        "\n",
        "    def predict(self,forest,X):\n",
        "        \"\"\"\n",
        "            Predict labels of X, using a decision forest\n",
        "            :param forest: A list of decision trees where each tree is a list of conjunctions\n",
        "            :param X: Numpy array of data instances\n",
        "            :return: class vector\n",
        "        \"\"\"\n",
        "        return np.argmax(self.predict_probas(forest,X),axis=1)\n",
        "\n",
        "    def get_forest_auc(self,forest,X,Y):\n",
        "        \"\"\"\n",
        "        Calculates predictions ROC AUC\n",
        "        :param forest: A list of lists of conjunctions\n",
        "        :param X: Numpy array of data instances\n",
        "        :param Y: Label vector\n",
        "        :return: ROC AUC\n",
        "        \"\"\"\n",
        "        y_probas = self.predict_probas(forest,X)\n",
        "        return get_auc(Y,y_probas)\n",
        "\n",
        "    def forests_kappa_score(self,probas1,probas2):\n",
        "        \"\"\"\n",
        "        Calculates Cohen's kappa of the predictions divided from two vectors of class probabilities\n",
        "        :param probas1: list of class probabilities\n",
        "        :param probas2: list of class probabilities\n",
        "        :return: Cohen's kappa\n",
        "        \"\"\"\n",
        "\n",
        "        predictions1 = np.array([np.argmax(i) for i in probas1])\n",
        "        predictions2 = np.array([np.argmax(i) for i in probas1])\n",
        "        return cohen_kappa_score(predictions1,predictions2)\n",
        "\n",
        "    def kappa_based_pruning(self,forest,X,Y,min_forest_size=10):\n",
        "        \"\"\"\n",
        "        This method conduct a kappa-based ensemble pruning.\n",
        "        :param forest: A list of lists of conjunctions (a decision forest)\n",
        "        :param X: Numpy array (data instances)\n",
        "        :param Y: Label vector\n",
        "        :param min_forest_size: minimum size of the pruned ensemble\n",
        "        :return: list of lists of conjunctions - represents the pruned ensemble\n",
        "        The algorithm contains the following stages:\n",
        "        1. Add the tree with the highest AUC for X to the new (empty) forest\n",
        "        2. At each iteration add the tree with the highest cohen's kappa in relation to the new forest\n",
        "        3. Stop when the new forest AUC doesn't improve and minimum forest size was reached\n",
        "        \"\"\"\n",
        "\n",
        "        selected_indexes = [np.argmax([self.get_forest_auc([t],X,Y) for t in forest])] #Include only the tree with the best AUC\n",
        "        previous_auc = 0\n",
        "        current_auc = get_auc(Y,self.predict_probas([forest[selected_indexes[0]]],X))\n",
        "        new_forest = [forest[selected_indexes[0]]]\n",
        "        while current_auc > previous_auc or len(new_forest) <= min_forest_size:\n",
        "            kappas = [1 if i in selected_indexes else self.forests_kappa_score(new_forest,[t],X) for i,t in enumerate(forest)]\n",
        "            new_index = np.argmin(kappas)\n",
        "            if new_index in selected_indexes:\n",
        "                break\n",
        "            selected_indexes.append(new_index)\n",
        "            previous_auc = current_auc\n",
        "            new_forest.append(forest[new_index])\n",
        "            current_auc = get_auc(Y,self.predict_probas(new_forest,X))\n",
        "        return new_forest\n",
        "\n",
        "    def max_auc_pruning(self, forest, X, Y, min_forest_size=10):\n",
        "        \"\"\"\n",
        "        This method conduct an ensemble pruning using a greedy algorithm that maximizes the AUC on the given dataset.\n",
        "        :param forest: A list of lists of conjunctions (a decision forest)\n",
        "        :param X: Numpy array (data instances)\n",
        "        :param Y: Label vector\n",
        "        :param min_forest_size: minimum size of the pruned ensemble\n",
        "        :return: list of lists of conjunctions - represents the pruned ensemble\n",
        "        \"\"\"\n",
        "        X = X.values\n",
        "        trees_predictions = {i: self.predict_probas_tree(forest[i],X) for i in range(len(forest))} #predictions are stored beforehand for efficiency purposes\n",
        "        selected_indexes = [np.argmax([get_auc(Y,trees_predictions[i]) for i in trees_predictions])] #get the tree with the highest AUC for the given dataset\n",
        "        previous_auc = 0\n",
        "        best_auc = get_auc(Y,trees_predictions[selected_indexes[0]])\n",
        "        while best_auc > previous_auc or len(selected_indexes) <= min_forest_size:\n",
        "            previous_auc = best_auc\n",
        "            best_index = None\n",
        "            for i in range(len(forest)):\n",
        "                if i in selected_indexes:\n",
        "                    continue\n",
        "                probas = np.array([trees_predictions[indx] for indx in selected_indexes + [i]]) #get the probas given by each tree, included the tested one\n",
        "                probas = np.array([softmax(prob)[0] for prob in probas.sum(axis=0)]) #aggregate the predictions\n",
        "                temp_auc = get_auc(Y,probas)\n",
        "                if temp_auc > best_auc or best_index==None:\n",
        "                    best_auc = temp_auc\n",
        "                    best_index = i\n",
        "            selected_indexes.append(best_index)\n",
        "        print('Pruned forest training set AUC: '+str(best_auc))\n",
        "        return [t for i,t in enumerate(forest) if i in selected_indexes]"
      ],
      "metadata": {
        "id": "ZR1YfBkhJsOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conjunction"
      ],
      "metadata": {
        "id": "X4HgsYMMKR7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contains the conjunction class\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "class Conjunction():\n",
        "    \"\"\"\n",
        "    A conjunction is a combination of feature bounds mapped into a class probability vector\n",
        "    \"\"\"\n",
        "    def __init__(self,feature_names,label_names,leaf_index=None,label_probas=None):\n",
        "        \"\"\"\n",
        "        :param feature_names: list of strings. Also determine the dimensionality\n",
        "        :param label_names: list of labels. Determines the number of labels too\n",
        "        :param leaf_index: This feature is optional. Can be relevant if we'd like to document the leaves that were used from the input forest\n",
        "        :param label_probas: also optional. Relevant if we'd like to determine the class probabilities within the constructor\n",
        "        \"\"\"\n",
        "        self.feature_names = feature_names\n",
        "        self.number_of_features = len(feature_names)\n",
        "        self.label_names = label_names\n",
        "\n",
        "        # upper and lower bounds of the feature for each rule\n",
        "        self.features_upper = [np.inf] * len(feature_names)\n",
        "        self.features_lower = [-np.inf] * len(feature_names)\n",
        "\n",
        "        self.label_probas = np.array(label_probas)\n",
        "        self.leaf_index = leaf_index\n",
        "\n",
        "        #The following dict is used for excluding irrelevant merges of different dummy variables that come from the same categorical feature\n",
        "        self.categorical_features_dict={}\n",
        "\n",
        "    def addCondition(self, feature, threshold, bound):\n",
        "        \"\"\"\n",
        "        This method adds a condition to the conjunction if relevant (rule isn't already contained in the conjunction)\n",
        "        :param feature: relevant feature\n",
        "        :param threshold: upper\\lower bound\n",
        "        :param bound: bound direction\n",
        "        \"\"\"\n",
        "        #Check if the rule isn't already contained in the conjunction\n",
        "        if bound == 'lower':\n",
        "            if self.features_lower[feature] < threshold:\n",
        "                self.features_lower[feature] = threshold\n",
        "        else:\n",
        "            if self.features_upper[feature] > threshold:\n",
        "                self.features_upper[feature] = threshold\n",
        "\n",
        "        #Address categorical features:\n",
        "        if '=' in self.feature_names[feature] and threshold >= 1 and bound == 'lower':\n",
        "            splitted = self.feature_names[feature].split('=')\n",
        "            self.categorical_features_dict[splitted[0]] = splitted[1]\n",
        "\n",
        "    def isContradict(self, other_conjunction):\n",
        "        \"\"\"\n",
        "        :param other_conjunction: conjunction object\n",
        "        :return: True if other and self have at least one contradiction, otherwise False\n",
        "        \"\"\"\n",
        "\n",
        "        #Check upper and lower bounds contradiction\n",
        "        for i in range(self.number_of_features):\n",
        "            if self.features_upper[i] <= other_conjunction.features_lower[i] or self.features_lower[i] >=  other_conjunction.features_upper[i]:\n",
        "                return True\n",
        "\n",
        "        # check for categorical features contradiction\n",
        "        for feature in self.feature_names:\n",
        "            if feature in self.categorical_features_dict and feature in other_conjunction.categorical_features_dict:\n",
        "                if self.categorical_features_dict[feature] != other_conjunction.categorical_features_dict[feature]:\n",
        "                    return True\n",
        "\n",
        "    def merge(self, other):\n",
        "        \"\"\"\n",
        "        :param other: conjunction\n",
        "        :return: new_conjunction - a merge of the self conjunction with other\n",
        "        \"\"\"\n",
        "        new_conjunction = Conjunction(self.feature_names,self.label_names,\n",
        "                                      self.leaf_index+other.leaf_index,self.label_probas+other.label_probas)\n",
        "        new_conjunction.features_upper = [min(i,j) for i,j in zip(self.features_upper,other.features_upper)]\n",
        "        new_conjunction.features_lower = [max(i, j) for i, j in zip(self.features_lower, other.features_lower)]\n",
        "        new_conjunction.categorical_features_dict = self.categorical_features_dict\n",
        "        new_conjunction.categorical_features_dict.update(other.categorical_features_dict)\n",
        "        return new_conjunction\n",
        "\n",
        "    def containsInstance(self,inst):\n",
        "        \"\"\"\n",
        "        Checks whether the input instance falls under the conjunction\n",
        "        :param inst:\n",
        "        :return: True if\n",
        "        \"\"\"\n",
        "        for i, lower, upper in zip(range(len(inst)), self.features_lower, self.features_upper):\n",
        "            if inst[i] >= upper or inst[i] < lower:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def has_low_interval(self,lowest_intervals):\n",
        "        for lower,upper,interval in zip(self.features_lower,self.features_upper,lowest_intervals):\n",
        "            if upper-lower<interval:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def predict_probas(self):\n",
        "        \"\"\"\n",
        "        :return: softmax of the result vector\n",
        "        \"\"\"\n",
        "\n",
        "        return softmax(self.label_probas)\n",
        "\n",
        "    def toString(self):\n",
        "        \"\"\"\n",
        "        This function creates a string representation of the conjunction (only for demonstration purposes)\n",
        "        \"\"\"\n",
        "        s = \"\"\n",
        "        #save lower bounds\n",
        "        for feature, threshold in enumerate(self.features_lower):\n",
        "            if threshold != (-np.inf):\n",
        "                s +=  self.feature_names[feature] + ' >= ' + str(np.round(threshold,3)) + \", \"\n",
        "        #save upper bounds\n",
        "        for feature, threshold in enumerate(self.features_upper):\n",
        "            if threshold != np.inf:\n",
        "                s +=  self.feature_names[feature] + ' < ' + str(np.round(threshold,3)) + \", \"\n",
        "        #save labels\n",
        "        s += 'labels: ['\n",
        "        s+=str(self.label_probas)\n",
        "        s += ']'\n",
        "        return s\n",
        "\n",
        "    #From here on everything is still tested\n",
        "    def get_data_point(self, min_values, max_values, mean_values):\n",
        "        X = []\n",
        "        for i,feature in enumerate(self.feature_names):\n",
        "            if self.features_lower[i]==-np.inf and self.features_upper[i]==np.inf:\n",
        "                X.append(mean_values[feature])\n",
        "            else:\n",
        "                X.append(np.mean([max(min_values[feature],self.features_lower[i]), min(max_values[feature],self.features_upper[i])]))\n",
        "        return np.array(X)"
      ],
      "metadata": {
        "id": "RGGrg5x9KSEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree Extraction"
      ],
      "metadata": {
        "id": "Sus8TWIEKIoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contains functions for extracting information of individual trees from XGBoost\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "#internal node parser:\n",
        "feature_regex = re.compile('\\D+(?P<node_index>\\d+):\\[(?P<feature>[^<]+)<(?P<value>[^\\]]+)\\D+(?P<left>\\d+)\\D+(?P<right>\\d+)\\D+(?P<missing>\\d+)')\n",
        "\n",
        "#leaf parser:\n",
        "leaf_regex = re.compile('\\D+(?P<node_index>\\d+)[^\\=]+=(?P<prediction>.+)')\n",
        "\n",
        "def extractNodesFromModel(model):\n",
        "    \"\"\"\n",
        "    Extract decision trees from XGBoost.\n",
        "    :param model: XGBoost model\n",
        "    :param feature_dict: {feature_name: feature_index}\n",
        "    :return: trees: List of trees where trees represented as lists of dictionaries. Each dictionary represents a node within the corresponding tree\n",
        "    \"\"\"\n",
        "    trees= []\n",
        "    for tree_string in model._Booster.get_dump():\n",
        "        nodes = [feature_regex.search('t' + node).groupdict() if '[' in node else leaf_regex.search('t' +node).groupdict() for node in tree_string.split('\\n')[:-1]]\n",
        "        trees.append(nodes)\n",
        "    return trees\n",
        "\n",
        "def extractClassValue(tree,leaf_index,label_names,class_index):\n",
        "    \"\"\"\n",
        "    This function takes a leaf index and convert the class logit into a probability\n",
        "    :param tree: dictionary that represents a decision tree\n",
        "    :param leaf_index: leaf index - integer\n",
        "    :param label_names: list of strings - labels\n",
        "    :param class_index: index of the addressed class\n",
        "    :return: class probabilitis\n",
        "    \"\"\"\n",
        "    pred = float(tree[leaf_index]['prediction'])\n",
        "    if len(label_names)>2:\n",
        "        return [pred if i == class_index else 0 for i in range(len(label_names))]\n",
        "    else:\n",
        "        p = 1 / (1 + np.exp(pred))\n",
        "        return [p,1-p]\n",
        "def extractConjunctionsFromTree(tree, tree_index,leaf_index, feature_dict, label_names, class_index):\n",
        "    \"\"\"\n",
        "    Covert the leaves of a tree into a set of conjunctions\n",
        "    :param tree: list of dictionaries where each dictionary represents a node within a tree\n",
        "    :param leaf_index: index of the currently processed node\n",
        "    :param feature_dict: {feature name: feature index} - for converting xgboost feature names to conjunction feature indices\n",
        "    :param label_names: possible class values\n",
        "    :param class_index: currently addressed class - since each model is basically a binary classification of tree of a single class it's impoertant to know the relevant class\n",
        "    :return: A set of conjunctions\n",
        "    \"\"\"\n",
        "    if 'prediction' in tree[leaf_index]:\n",
        "        probas = extractClassValue(tree,leaf_index,label_names,class_index)\n",
        "        return [Conjunction(list(feature_dict.keys()),label_names,\n",
        "                            leaf_index=[str(tree_index)+'_'+str(leaf_index)],label_probas=probas)]\n",
        "    l_conjunctions = extractConjunctionsFromTree(tree,tree_index,int(tree[leaf_index]['left']),feature_dict,label_names,class_index)\n",
        "    r_conjunctions = extractConjunctionsFromTree(tree,tree_index,int(tree[leaf_index]['right']),feature_dict,label_names,class_index)\n",
        "    for c in l_conjunctions:\n",
        "        c.addCondition(feature_dict[tree[leaf_index]['feature']],float(tree[leaf_index]['value']),'upper')\n",
        "    for c in r_conjunctions:\n",
        "        c.addCondition(feature_dict[tree[leaf_index]['feature']],float(tree[leaf_index]['value']),'lower')\n",
        "    return l_conjunctions + r_conjunctions\n",
        "\n",
        "def merge_two_conjunction_sets(conj_list1,conj_list2):\n",
        "    \"\"\"\n",
        "    Gets two conjunction sets and return a set that is a cartesian product of the two input sets\n",
        "    :param conj_list1:\n",
        "    :param conj_list2:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    new_conjunction_list=[]\n",
        "    for c1 in conj_list1:\n",
        "        for c2 in conj_list2:\n",
        "            if not c1.isContradict(c2):\n",
        "                new_conjunction_list.append(c1.merge(c2))\n",
        "    return new_conjunction_list\n",
        "\n",
        "def postProcessTrees(conjunction_sets, num_of_labels):\n",
        "    \"\"\"\n",
        "    This function is used for integrating mulitple binary trees into a single tree of multiple labels\n",
        "    :param conjunction_sets: list of lists of conjunctions\n",
        "    :param num_of_labels: number of labels in the dataset that was used for training\n",
        "    :return: new list of conjunctions\n",
        "    \"\"\"\n",
        "\n",
        "    new_conj_list = []\n",
        "    for i in range(0, len(conjunction_sets), num_of_labels):\n",
        "        conj = conjunction_sets[i]\n",
        "        for j in range(i + 1, i + num_of_labels):\n",
        "            conj = merge_two_conjunction_sets(conj, conjunction_sets[j])\n",
        "        new_conj_list.append(conj)\n",
        "    return new_conj_list\n",
        "\n",
        "def extractConjunctionSetsFromForest(model,unique_labels,features):\n",
        "    \"\"\"\n",
        "    This function takes XGBoost model and returns a list of trees where each tree is represented as a list of conjunctions.\n",
        "    Each of the tree conjunctions stands for a single decision path\n",
        "    :param model: XGBoost model\n",
        "    :param unique_labels: label names\n",
        "    :param features: feature names\n",
        "    :return: a list of conjunctions\n",
        "    \"\"\"\n",
        "\n",
        "    trees = extractNodesFromModel(model)\n",
        "    num_of_labels = len(unique_labels)\n",
        "    feature_dict = {v:k for k,v in enumerate(features)}\n",
        "    conjunction_sets = {}\n",
        "    for i,t in enumerate(trees): #i stands for the corresponding class index\n",
        "        indexed_tree = {int(v['node_index']): v for v in t}\n",
        "        conjunction_sets[i] = extractConjunctionsFromTree(indexed_tree,i,0, feature_dict, unique_labels, i % num_of_labels)\n",
        "    if num_of_labels > 2:\n",
        "        return postProcessTrees(conjunction_sets,num_of_labels)\n",
        "    else:\n",
        "        return list(conjunction_sets.values())"
      ],
      "metadata": {
        "id": "VFm7VuGOKI41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conjunction Set"
      ],
      "metadata": {
        "id": "3dRUmQNUJ1wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu0sVee5Kj3w",
        "outputId": "50aa983f-d0c5-46c1-a195-6143cc8e6ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-0.9.9.tar.gz (116 kB)\n",
            "\u001b[?25l\r\u001b[K     |                             | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |                          | 20 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |                       | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |                    | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |                  | 51 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |               | 61 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |            | 71 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |         | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |      | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |   | 102 kB 9.8 MB/s eta 0:00:01\r\u001b[K     | | 112 kB 9.8 MB/s eta 0:00:01\r\u001b[K     || 116 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.21.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (0.34.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pyod) (3.10.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->pyod) (2018.9)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.9-py3-none-any.whl size=139325 sha256=9803408191323aaa495f6d1d2bb4a7e4dae234b8532f14e6a74910a7882b5858\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/32/f0/0dc3050775e77b6661a116b70817b02b4305fa253269d6d998\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-0.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contains the ConjunctionSet class\n",
        "\"\"\"\n",
        "\n",
        "from statsmodels.distributions.empirical_distribution import ECDF\n",
        "from collections import Counter\n",
        "import pyod\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.lof import LOF\n",
        "\n",
        "class ConjunctionSet():\n",
        "    \"\"\"\n",
        "    ConjunctionSet is a class that represents a set of conjunctions.\n",
        "    This is the output of stage 1.\n",
        "    Each conjunction at the given set represents a possible combination of leaves from the source decision forests.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_number_of_conjunctions=np.inf, filter_method='probability'):\n",
        "        \"\"\"\n",
        "        :param max_number_of_conjunctions: Number of maximum allowed conjunctions at each iteration\n",
        "        :param filter_method: The approach that will be takes for filtering conjunctions\n",
        "        \"\"\"\n",
        "        self.filter_method = filter_method\n",
        "        self.max_number_of_conjunctions = max_number_of_conjunctions\n",
        "\n",
        "    def fit(self,trees_conjunctions,data,feature_cols,label_col, int_features = []):\n",
        "        \"\"\"\n",
        "        :param trees_conjunctions: Decision forest given as a list of lists of conjunction objects.\n",
        "        :param data: pandas dataframe that was used for training the decision forest\n",
        "        :param feature_cols: Feature names in the dataframe\n",
        "        :param label_col: label column name\n",
        "        :param int_features: list of integer feartures\n",
        "        :return: set a list of conjunction set that best represents the decision forest\n",
        "        \"\"\"\n",
        "        self.feature_cols = feature_cols\n",
        "        self.labels = data[label_col].unique()\n",
        "        self.trees_conjunctions = trees_conjunctions\n",
        "        self.int_features = int_features\n",
        "\n",
        "        #Create an ECDF for each feature\n",
        "        self.set_probability_ecdf(data)\n",
        "\n",
        "\n",
        "        #Extract all the leaf combinations that were applied for training data:\n",
        "        print('Create conjunction set from training data instances')\n",
        "        self.create_conjunction_set_from_data(data)\n",
        "\n",
        "\n",
        "        #set maximum number of conjunctions per label\n",
        "        print('Create complete conjunction set')\n",
        "        self.calculate_max_conjunctions_per_label(data,label_col)\n",
        "\n",
        "        # Run the algorithm of creating the complete conjunction set:\n",
        "        self.createConjunctionSetFromTreeConjunctions()\n",
        "\n",
        "        #Merge the two conjunctions:\n",
        "        self.conjunctions = self.conjunctions + self.training_conjunctions\n",
        "\n",
        "        #Get the ordered splitting points for creating the hierarchy at stage 2\n",
        "        self.set_ordered_splitting_points()\n",
        "\n",
        "    def createConjunctionSetFromTreeConjunctions(self):\n",
        "        \"\"\"\n",
        "        This method generates the conjunction set (stage 1) from the decision forest\n",
        "        \"\"\"\n",
        "        self.conjunctions = self.trees_conjunctions[0] #Define the first tree as the current conjunction set\n",
        "        i = 1\n",
        "        self.size_per_iteration = [len(self.conjunctions)]\n",
        "        while i < len(self.trees_conjunctions): #At each iteration we merge the next tree with the current conjunction set\n",
        "            self.conjunctions= merge_two_conjunction_sets(self.conjunctions, self.trees_conjunctions[i])\n",
        "            i+=1\n",
        "            self.filter() #Filter redundant conjunction according to the filtering strategy\n",
        "            self.size_per_iteration.append(len(self.conjunctions))\n",
        "            print('Size at iteration '+str(i)+': '+str(len(self.conjunctions)))\n",
        "    def filter(self):\n",
        "        \"\"\"\n",
        "        This method filters the current conjunction set according to the filtering strategy.\n",
        "        At the first stage it filters conjunctions that contain irrelevant integer rules.\n",
        "        For example: If x is an integer then a conjunction that contains  5.5 >= x < 6 is filtered out\n",
        "        \"\"\"\n",
        "        self.conjunctions = [conj for conj in self.conjunctions if self.int_filter(conj)]\n",
        "        if len(self.conjunctions)<=self.max_number_of_conjunctions:\n",
        "            return\n",
        "        if self.filter_method == 'probability':\n",
        "            self.filter_by_probability()\n",
        "        if self.filter_method == 'probability_label':\n",
        "            self.filter_by_probability_labels()\n",
        "        elif self.filter_method == 'knn':\n",
        "            self.filter_by_knn()\n",
        "        elif self.filter_method == 'LOF':\n",
        "            self.filter_by_lof()\n",
        "\n",
        "    def filter_by_probability(self,EPSILON=0.00001):\n",
        "        \"\"\"\n",
        "        This method filters conjunctions according to the product of each rule ECDF\n",
        "        :param EPSILON: Prevent a case of probability = 0\n",
        "        \"\"\"\n",
        "        independent_probs = []\n",
        "        for conj in self.conjunctions:\n",
        "            independent_probs.append(np.sum(np.log([self.ecdf[col](conj.features_upper[col])-self.ecdf[col](conj.features_lower[col])+EPSILON for\n",
        "                                                         col in range(len(self.feature_cols))])))\n",
        "        max_value = sorted(independent_probs, reverse=True)[self.max_number_of_conjunctions]\n",
        "        self.conjunctions = [c for c,val in zip(self.conjunctions,independent_probs) if val >= max_value] #It actually includes a little more than max_number_of conjunctions due to the >=\n",
        "\n",
        "    def predict(self,X):\n",
        "        return [np.argmax(i) for i in self.predict_proba(X)]\n",
        "\n",
        "    def predict_proba(self,X):\n",
        "        predictions = []\n",
        "        if isinstance(X,pd.DataFrame):\n",
        "            X = X[self.feature_cols].values\n",
        "        for inst in X:\n",
        "            for conjunction in self.conjunctions:\n",
        "                if conjunction.containsInstance(inst):\n",
        "                    predictions.append(np.exp(conjunction.label_probas) / np.sum(np.exp(conjunction.label_probas), axis=0)) #softmax\n",
        "                    break\n",
        "        return np.array(predictions)\n",
        "\n",
        "    #Filtering functions\n",
        "\n",
        "    def set_probability_ecdf(self,data):\n",
        "        self.ecdf = {i:ECDF(data[col].values) for i,col in enumerate(self.feature_cols)}\n",
        "\n",
        "    def set_minimum_intervals(self,data):\n",
        "        intervals = {col: data[col].diff().sort_values().dropna().values for col in self.feature_cols}\n",
        "        self.minimum_intervals = [x[x > 0].min()*self.min_interval_ratio for col, x in intervals.items()]\n",
        "\n",
        "    def int_filter(self,conj,EPSILLON=0.00001):\n",
        "        for i,feature in enumerate(self.feature_cols):\n",
        "            if feature in self.int_features:\n",
        "                if conj.features_upper[i]-conj.features_lower[i]-EPSILLON <= 0.5 and (conj.features_lower[i] % 1) > 0:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    def create_conjunction_set_from_data(self,X):\n",
        "        \"\"\"\n",
        "        :param X: Pandas dataframe (or matrix)\n",
        "        :return: training_conjunctions - all the conjunctions that were applied for X\n",
        "        \"\"\"\n",
        "        participated_leaves = []\n",
        "        self.training_conjunctions = []\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = X[self.feature_cols].values\n",
        "        for inst in X:\n",
        "            s=''\n",
        "            conj = Conjunction(self.feature_cols,self.labels,leaf_index=[],label_probas=np.zeros(len(self.labels))) #Define the conjunction\n",
        "            for tree_index,tree in enumerate(self.trees_conjunctions):\n",
        "                for leaf_index,leaf in enumerate(tree):\n",
        "                    if leaf.containsInstance(inst):\n",
        "                        conj = conj.merge(leaf)\n",
        "                        s+=str(tree_index)+'|'+str(leaf_index)+'_'\n",
        "            if s not in participated_leaves:\n",
        "                self.training_conjunctions.append(conj)\n",
        "                participated_leaves.append(s)\n",
        "        print('Number of conjunctions created from data: '+str(len(self.training_conjunctions)))\n",
        "\n",
        "    def set_ordered_splitting_points(self):\n",
        "        \"\"\"\n",
        "        This method creates the splitting points for stage 2 (order the conjunctions in a hierarchical order)\n",
        "        \"\"\"\n",
        "        self.splitting_points = {i:[] for i in range(len(self.feature_cols))}\n",
        "        for tree in self.trees_conjunctions:\n",
        "            for leaf in tree:\n",
        "                for i,lower,upper in zip(range(len(self.feature_cols)),leaf.features_lower,leaf.features_upper):\n",
        "                    self.splitting_points[i].extend([upper,lower])\n",
        "        for i in self.splitting_points:\n",
        "            self.splitting_points[i] = [v[0] for v in Counter(self.splitting_points[i]).most_common() if np.abs(v[0]) < np.inf]\n",
        "\n",
        "    def filter_by_knn(self):\n",
        "        \"\"\"\n",
        "        Filter by KNN ANomaly detection method. Doesn't seem to be better than probability filtering for now\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        data_points = np.array([conj.get_data_point(self.min_values, self.max_values, self.mean_values)for conj in self.conjunctions]).reshape(len(self.conjunctions),len(self.feature_cols))\n",
        "        anomaly_probas = [i[1] for i in self.knn_clf.predict_proba(data_points)]\n",
        "        max_value = sorted(anomaly_probas)[self.max_number_of_conjunctions]\n",
        "        self.conjunctions = [c for c, val in zip(self.conjunctions, anomaly_probas) if val <= max_value]\n",
        "    def filter_by_lof(self):\n",
        "        \"\"\"\n",
        "        Filter by LOF ANomaly detection method. Doesn't seem to be better than probability filtering for now\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        data_points = np.array([conj.get_data_point(self.min_values, self.max_values, self.mean_values)for conj in self.conjunctions]).reshape(len(self.conjunctions),len(self.feature_cols))\n",
        "        anomaly_probas = [i[1] for i in self.lof_clf.predict_proba(data_points)]\n",
        "        max_value = sorted(anomaly_probas)[self.max_number_of_conjunctions]\n",
        "        self.conjunctions = [c for c, val in zip(self.conjunctions, anomaly_probas) if val <= max_value]\n",
        "\n",
        "    def calculate_max_conjunctions_per_label(self,data,label_col):\n",
        "        self.max_conjunctions_per_label = dict((data[label_col].value_counts(normalize=True)*self.max_number_of_conjunctions).astype(int))\n",
        "\n",
        "    def filter_by_probability_labels(self,EPSILON=0.00001):\n",
        "        \"\"\"\n",
        "        :param EPSILON: Added to the denominator to prevent devision by zero\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        conjunctions_dict = {}\n",
        "        probs_dict = {}\n",
        "\n",
        "        for indx,conj in enumerate(self.conjunctions):\n",
        "            conjunctions_dict[indx] = conj\n",
        "            probs_dict[indx] = np.sum(np.log(\n",
        "                [self.ecdf[col](conj.features_upper[col]) - self.ecdf[col](conj.features_lower[col]) + EPSILON for\n",
        "                 col in range(len(self.feature_cols))]))\n",
        "        probs_dict = dict(sorted(probs_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
        "        conjs_per_label = {label:0 for label in self.labels}\n",
        "        conjunctions = []\n",
        "        for indx in probs_dict:\n",
        "            conj = conjunctions_dict[indx]\n",
        "            label = np.argmax(conj.label_probas)\n",
        "            if conjs_per_label[label] < self.max_conjunctions_per_label[label]:\n",
        "                conjunctions.append(conj)\n",
        "                conjs_per_label[label]+=1\n",
        "            if len(conjunctions) == self.max_number_of_conjunctions:\n",
        "                break\n",
        "        self.conjunctions = conjunctions"
      ],
      "metadata": {
        "id": "GpbyW7kEJ17a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FBT"
      ],
      "metadata": {
        "id": "KDSe2NbJKw4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This module contains a forest based tree class (FBT).\n",
        "The class takes an XGBoost as an input and generates a decision aims at preserving the predictive performance of\n",
        "the XGboost model\n",
        "\"\"\"\n",
        "class FBT():\n",
        "    \"\"\"\n",
        "    This class creates a decision tree from an XGboost\n",
        "    \"\"\"\n",
        "    def __init__(self,max_depth,min_forest_size,max_number_of_conjunctions,pruning_method=None):\n",
        "        \"\"\"\n",
        "        :param max_depth: Maximum allowed depths of the generated tree\n",
        "        :param min_forest_size: Minimum size of the pruned forest (relevant for the pruning stage)\n",
        "        :param max_number_of_conjunctions:\n",
        "        :param pruning_method: Pruning method. If None then there's no pruning. 'auc' is for greedy auc-bsed pruning\n",
        "        :param xgb_model: Trained XGboost model\n",
        "        \"\"\"\n",
        "        self.min_forest_size = min_forest_size\n",
        "        self.max_number_of_conjunctions = max_number_of_conjunctions\n",
        "        self.pruning_method = pruning_method\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self,train,feature_cols,label_col, xgb_model, pruned_forest=None, trees_conjunctions_total=None):\n",
        "        \"\"\"\n",
        "        Generates the decision tree by applying the following stages:\n",
        "        1. Generating a conjunction set that represents each tree of the decision forest\n",
        "        2. Prune the decision forest according to the given pruning approach\n",
        "        3. Generate the conjunction set (stage 1 in the algorithm presented)\n",
        "        4. Create a decision tree out of the generated conjunction set\n",
        "        :param train: pandas dataframe that was used for training the XGBoost\n",
        "        :param feature_cols: feature column names\n",
        "        :param label_col: label column name\n",
        "        :param xgb_model: XGBoost\n",
        "        :param pruned_forest: A list of trees, represnt a post-pruning forest. Relevant mostly for the experiment presented in the paper\n",
        "        :param tree_conjunctions: This para\n",
        "        \"\"\"\n",
        "        self.feature_cols = feature_cols\n",
        "        self.label_col = label_col\n",
        "        self.int_cols = [k for k,v in train[feature_cols].dtypes.items() if 'int' in str(v)]\n",
        "        self.xgb_model = xgb_model\n",
        "        if pruned_forest is None or trees_conjunctions_total is None:\n",
        "            self.trees_conjunctions_total = extractConjunctionSetsFromForest(self.xgb_model,train[self.label_col].unique(),self.feature_cols)\n",
        "            print('Start pruning')\n",
        "            self.prune(train)\n",
        "        else:\n",
        "            self.pruner = Pruner()\n",
        "            self.trees_conjunctions_total = trees_conjunctions_total\n",
        "            self.trees_conjunctions = pruned_forest\n",
        "        self.cs = ConjunctionSet(max_number_of_conjunctions=self.max_number_of_conjunctions)\n",
        "        self.cs.fit(self.trees_conjunctions,train, feature_cols,label_col,int_features=self.int_cols)\n",
        "        print('Start ordering conjunction set in a tree structure')\n",
        "        self.tree = Tree(self.cs.conjunctions, self.cs.splitting_points,self.max_depth)\n",
        "        self.tree.split()\n",
        "        print('Construction of tree has been completed')\n",
        "\n",
        "    def prune(self,train):\n",
        "        \"\"\"\n",
        "        :param train: pandas dataframe used as a pruning dataset\n",
        "        :return: creates a pruned decision forest (include only the relevant trees)\n",
        "        \"\"\"\n",
        "        if self.pruning_method == None:\n",
        "            self.trees_conjunctions = self.trees_conjunctions_total\n",
        "        self.pruner = Pruner()\n",
        "        if self.pruning_method == 'auc':\n",
        "            self.trees_conjunctions = self.pruner.max_auc_pruning(self.trees_conjunctions_total, train[self.feature_cols],\n",
        "                                                                      train[self.label_col], min_forest_size=self.min_forest_size)\n",
        "\n",
        "    def predict_proba(self,X):\n",
        "        \"\"\"\n",
        "        Returns class probabilities\n",
        "        :param X: Pandas dataframe or a numpy matrix\n",
        "        :return: class probabilities for the corresponding data\n",
        "        \"\"\"\n",
        "        return self.tree.predict_proba(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Get predictions vector\n",
        "        :param X: Pandas dataframe or a numpy matrix\n",
        "        :return: Predicted classes\n",
        "        \"\"\"\n",
        "        return np.argmax(self.predict_proba(X), axis=1)\n",
        "\n",
        "    def get_decision_paths(self, X):\n",
        "        \"\"\"\n",
        "        :param X: Pandas data frame of [number_of_instances, number_of_features] dimension\n",
        "        :return: A list of decision paths where each decision path represented as a string of nodes. one node for the leaf and the other for the decision nodes\n",
        "        \"\"\"\n",
        "        paths = self.tree.get_decision_paths(X)\n",
        "        processed_paths = []\n",
        "        for path in paths:\n",
        "            temp_path = []\n",
        "            for node in path:\n",
        "                if node.startswith('label'):\n",
        "                    temp_path.append(node)\n",
        "                else:\n",
        "                    if '<' in node:\n",
        "                        splitted = node.split('<')\n",
        "                        temp_path.append(self.feature_cols[int(splitted[0])]+' < '+splitted[1])\n",
        "                    else:\n",
        "                        splitted = node.split('>=')\n",
        "                        temp_path.append(self.feature_cols[int(splitted[0])] + ' >= ' + splitted[1])\n",
        "            processed_paths.append(temp_path)\n",
        "        return processed_paths\n",
        "\n",
        "    #######################################################################\n",
        "    #The following functions are only relevant for the experiment\n",
        "    # They should be excluded from the documentation of the package\n",
        "    ########################################################################\n",
        "\n",
        "    def predict_proba_and_depth(self,X):\n",
        "        \"\"\"\n",
        "        Get class probabilities and depths for each instance\n",
        "        :param X: Pandas dataframe or a numpy matrix\n",
        "        :return: class probabilities and the depth of each prediction\n",
        "        \"\"\"\n",
        "        return self.tree.predict_proba_and_depth(X)\n",
        "\n",
        "    def predict_proba_pruned_forest(self,X):\n",
        "        \"\"\"\n",
        "        Predict_proba using the pruned forest\n",
        "        :param X: Pandas dataframe or a numpy matrix\n",
        "        :return: Class probabilities according to the pruned forest\n",
        "        \"\"\"\n",
        "        return self.pruner.predict_probas(self.trees_conjunctions,X)\n",
        "\n",
        "    def predict_proba_and_depth_forest(self,X):\n",
        "        \"\"\"\n",
        "                Predict_proba and depth using the original forest\n",
        "                :param X: Pandas dataframe or a numpy matrix\n",
        "                :return: Class probabilities according to the forest and corresponding depths\n",
        "        \"\"\"\n",
        "        probas = []\n",
        "        depths = []\n",
        "        for inst in X.values:\n",
        "            proba=[]\n",
        "            depth = 0\n",
        "            for t in self.trees_conjunctions_total:\n",
        "                for conj in t:\n",
        "                    if conj.containsInstance(inst):\n",
        "                        depth+= np.sum(np.abs(conj.features_upper)!=np.inf) + np.sum(np.abs(conj.features_lower)!=np.inf)\n",
        "                        proba.append(conj.label_probas)\n",
        "            depths.append(depth)\n",
        "            probas.append(softmax(np.array(proba).sum(axis=0)))\n",
        "        return np.array([i[0] for i in probas]), depths\n",
        "\n",
        "    def predict_proba_and_depth_pruned_forest(self,X):\n",
        "        \"\"\"\n",
        "        Predict_proba and depth using the pruned forest\n",
        "        :param X: Pandas dataframe or a numpy matrix\n",
        "        :return: Class probabilities according to the pruned forest and corresponding depths\n",
        "        \"\"\"\n",
        "        probas = []\n",
        "        depths = []\n",
        "        for inst in X.values:\n",
        "            proba=[]\n",
        "            depth = 0\n",
        "            for t in self.trees_conjunctions:\n",
        "                for conj in t:\n",
        "                    if conj.containsInstance(inst):\n",
        "                        depth+= np.sum(np.abs(conj.features_upper)!=np.inf) + np.sum(np.abs(conj.features_lower)!=np.inf)\n",
        "                        proba.append(conj.label_probas)\n",
        "            depths.append(depth)\n",
        "            probas.append(softmax(np.array(proba).sum(axis=0)))\n",
        "        return np.array([i[0] for i in probas]), depths"
      ],
      "metadata": {
        "id": "5ETf0RPsKxAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test of the GitHub code"
      ],
      "metadata": {
        "id": "_p7rrX4ff6UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_col = 'Rating (Num)'\n",
        "X_names = list(Data1.columns)[1:]\n",
        "lab = [i+1 for i in range(20)]\n",
        "lab.pop(1)\n",
        "xg_cl = xg.XGBClassifier(max_depth = 3, n_estimators=10).fit(Data1[X_names][:744], Data1[label_col][:744])"
      ],
      "metadata": {
        "id": "Ff0O-xssgD1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_prob = xg_cl.predict_proba(Data1[X_names][:744])"
      ],
      "metadata": {
        "id": "f2IgWZAqpq-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = np.dot(Y_prob,lab)"
      ],
      "metadata": {
        "id": "bU_qSfEbqF4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fbt = FBT(max_depth=10,max_number_of_conjunctions=500,min_forest_size=10,pruning_method='auc')\n",
        "fbt.fit(Data1,X_names,label_col, xg_cl)"
      ],
      "metadata": {
        "id": "hc__2XYrgOrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cs = fbt.cs()\n",
        "a = cs.toString()"
      ],
      "metadata": {
        "id": "QSd6gBp6EQNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = fbt.tree"
      ],
      "metadata": {
        "id": "C0Bhl2trEWvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = fbt.get_decision_paths(Data1[feature_cols][:744])\n",
        "l_2021 = fbt.get_decision_paths(Data1[feature_cols][744:])"
      ],
      "metadata": {
        "id": "5lA0xIsogOwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = Data1.values[0:744,1:7]\n",
        "Y = Data1.values[0:744,0]\n",
        "Y_pred = np.dot(fbt.predict_prob(Data1[X_names][:744], lab)\n",
        "n = len(Y)\n",
        "exact = 0\n",
        "N1 = 0\n",
        "N2 = 0\n",
        "N3 = 0\n",
        "for i in range(n):\n",
        "  if abs(Y[i]-Y_pred[i])<3:\n",
        "    N3+=1\n",
        "    if abs(Y[i]-Y_pred[i])<2:\n",
        "      N2+=1\n",
        "      if abs(Y[i]-Y_pred[i])<1:\n",
        "        N1+=1\n",
        "        if abs(Y[i]-Y_pred[i])<0.5:\n",
        "          exact+=1\n",
        "exact=(exact/n)*100\n",
        "N1 = (N1/n)*100\n",
        "N2 = (N2/n)*100\n",
        "N3 = (N3/n)*100\n",
        "print('Result on the TRAINING SET')\n",
        "print('The mean error is of {} notches'.format(np.mean(abs(Y-Y_pred))))\n",
        "print('We have {}% of exact prediction '.format(round(exact, 4)))\n",
        "print('We have {}% of prediction within 1 notche'.format(round(N1, 4)))\n",
        "print('We have {}% of prediction within 2 notches'.format(round(N2, 4)))\n",
        "print('We have {}% of prediction within 3 notches'.format(round(N3, 4)))"
      ],
      "metadata": {
        "id": "UsOAwYuSq108"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_2021 = Data1.values[744:,1:7]\n",
        "Y = Data1.values[744:,0]\n",
        "Y_pred = np.dot(fbt.predict_prob(Data1[X_names][744:], lab)\n",
        "n = len(Y)\n",
        "exact = 0\n",
        "N1 = 0\n",
        "N2 = 0\n",
        "N3 = 0\n",
        "for i in range(n):\n",
        "  if abs(Y[i]-Y_pred[i])<3:\n",
        "    N3+=1\n",
        "    if abs(Y[i]-Y_pred[i])<2:\n",
        "      N2+=1\n",
        "      if abs(Y[i]-Y_pred[i])<1:\n",
        "        N1+=1\n",
        "        if abs(Y[i]-Y_pred[i])<0.5:\n",
        "          exact+=1\n",
        "exact=(exact/n)*100\n",
        "N1 = (N1/n)*100\n",
        "N2 = (N2/n)*100\n",
        "N3 = (N3/n)*100\n",
        "print('Result on the TEST SET')\n",
        "print('The mean error is of {} notches'.format(np.mean(abs(Y-Y_pred))))\n",
        "print('We have {}% of exact prediction'.format(round(exact, 4)))\n",
        "print('We have {}% of prediction within 1 notche'.format(round(N1, 4)))\n",
        "print('We have {}% of prediction within 2 notches'.format(round(N2, 4)))\n",
        "print('We have {}% of prediction within 3 notches'.format(round(N3, 4)))"
      ],
      "metadata": {
        "id": "zu9fNIqNrU-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}